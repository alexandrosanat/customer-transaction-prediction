{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74987dec-c44d-44b6-8b80-317681400fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b8b7d-fb57-423c-8157-e9387c9ed7fb",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de951eb6-da9b-4d97-8521-aa547873bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/processed_train.csv\")\n",
    "test = pd.read_csv(\"./data/processed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cdc55c-9fd6-4045-8c5c-7ecd93d4ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('target')\n",
    "train.drop('ID_code', inplace=True, axis=1)\n",
    "X_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c0c0db-327a-491f-bb62-c1cb8b98b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b9e286-7cfb-4abe-a664-c576b6f70fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_val, y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84bd7f-7efe-4f3b-9f0b-5b4207bb7f7a",
   "metadata": {},
   "source": [
    "### 2. Model Training - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dba8f9-210f-4085-a1be-d6836be98b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = xgboost.XGBClassifier(learning_rate=0.1,\n",
    "                                      max_depth=5,\n",
    "                                      n_estimators=5000,\n",
    "                                      subsample=0.5,\n",
    "                                      colsample_bytree=0.5,\n",
    "                                      eval_metric='auc',\n",
    "                                      verbosiry=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e90c60-5de8-4163-b88e-7641fb9c698a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:03:47] WARNING: ..\\src\\learner.cc:573: \n",
      "Parameters: { \"verbosiry\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.61756\n",
      "[1]\tvalidation_0-auc:0.65707\n",
      "[2]\tvalidation_0-auc:0.67953\n",
      "[3]\tvalidation_0-auc:0.68938\n",
      "[4]\tvalidation_0-auc:0.69498\n",
      "[5]\tvalidation_0-auc:0.70060\n",
      "[6]\tvalidation_0-auc:0.70537\n",
      "[7]\tvalidation_0-auc:0.71301\n",
      "[8]\tvalidation_0-auc:0.71864\n",
      "[9]\tvalidation_0-auc:0.72294\n",
      "[10]\tvalidation_0-auc:0.73241\n",
      "[11]\tvalidation_0-auc:0.73389\n",
      "[12]\tvalidation_0-auc:0.73659\n",
      "[13]\tvalidation_0-auc:0.74013\n",
      "[14]\tvalidation_0-auc:0.74220\n",
      "[15]\tvalidation_0-auc:0.74465\n",
      "[16]\tvalidation_0-auc:0.74621\n",
      "[17]\tvalidation_0-auc:0.74742\n",
      "[18]\tvalidation_0-auc:0.75623\n",
      "[19]\tvalidation_0-auc:0.76043\n",
      "[20]\tvalidation_0-auc:0.76350\n",
      "[21]\tvalidation_0-auc:0.76632\n",
      "[22]\tvalidation_0-auc:0.77019\n",
      "[23]\tvalidation_0-auc:0.77194\n",
      "[24]\tvalidation_0-auc:0.77376\n",
      "[25]\tvalidation_0-auc:0.77340\n",
      "[26]\tvalidation_0-auc:0.77576\n",
      "[27]\tvalidation_0-auc:0.77982\n",
      "[28]\tvalidation_0-auc:0.78201\n",
      "[29]\tvalidation_0-auc:0.78414\n",
      "[30]\tvalidation_0-auc:0.78828\n",
      "[31]\tvalidation_0-auc:0.79047\n",
      "[32]\tvalidation_0-auc:0.79440\n",
      "[33]\tvalidation_0-auc:0.79573\n",
      "[34]\tvalidation_0-auc:0.79700\n",
      "[35]\tvalidation_0-auc:0.79751\n",
      "[36]\tvalidation_0-auc:0.79925\n",
      "[37]\tvalidation_0-auc:0.80071\n",
      "[38]\tvalidation_0-auc:0.80230\n",
      "[39]\tvalidation_0-auc:0.80425\n",
      "[40]\tvalidation_0-auc:0.80555\n",
      "[41]\tvalidation_0-auc:0.80753\n",
      "[42]\tvalidation_0-auc:0.80885\n",
      "[43]\tvalidation_0-auc:0.81120\n",
      "[44]\tvalidation_0-auc:0.81315\n",
      "[45]\tvalidation_0-auc:0.81480\n",
      "[46]\tvalidation_0-auc:0.81615\n",
      "[47]\tvalidation_0-auc:0.81717\n",
      "[48]\tvalidation_0-auc:0.81909\n",
      "[49]\tvalidation_0-auc:0.82063\n",
      "[50]\tvalidation_0-auc:0.82082\n",
      "[51]\tvalidation_0-auc:0.82273\n",
      "[52]\tvalidation_0-auc:0.82381\n",
      "[53]\tvalidation_0-auc:0.82595\n",
      "[54]\tvalidation_0-auc:0.82696\n",
      "[55]\tvalidation_0-auc:0.82750\n",
      "[56]\tvalidation_0-auc:0.82823\n",
      "[57]\tvalidation_0-auc:0.82881\n",
      "[58]\tvalidation_0-auc:0.83019\n",
      "[59]\tvalidation_0-auc:0.83058\n",
      "[60]\tvalidation_0-auc:0.83099\n",
      "[61]\tvalidation_0-auc:0.83213\n",
      "[62]\tvalidation_0-auc:0.83250\n",
      "[63]\tvalidation_0-auc:0.83361\n",
      "[64]\tvalidation_0-auc:0.83443\n",
      "[65]\tvalidation_0-auc:0.83515\n",
      "[66]\tvalidation_0-auc:0.83656\n",
      "[67]\tvalidation_0-auc:0.83811\n",
      "[68]\tvalidation_0-auc:0.83886\n",
      "[69]\tvalidation_0-auc:0.83910\n",
      "[70]\tvalidation_0-auc:0.84016\n",
      "[71]\tvalidation_0-auc:0.84073\n",
      "[72]\tvalidation_0-auc:0.84085\n",
      "[73]\tvalidation_0-auc:0.84177\n",
      "[74]\tvalidation_0-auc:0.84222\n",
      "[75]\tvalidation_0-auc:0.84271\n",
      "[76]\tvalidation_0-auc:0.84359\n",
      "[77]\tvalidation_0-auc:0.84404\n",
      "[78]\tvalidation_0-auc:0.84447\n",
      "[79]\tvalidation_0-auc:0.84501\n",
      "[80]\tvalidation_0-auc:0.84623\n",
      "[81]\tvalidation_0-auc:0.84678\n",
      "[82]\tvalidation_0-auc:0.84723\n",
      "[83]\tvalidation_0-auc:0.84779\n",
      "[84]\tvalidation_0-auc:0.84853\n",
      "[85]\tvalidation_0-auc:0.84911\n",
      "[86]\tvalidation_0-auc:0.84977\n",
      "[87]\tvalidation_0-auc:0.85037\n",
      "[88]\tvalidation_0-auc:0.85074\n",
      "[89]\tvalidation_0-auc:0.85104\n",
      "[90]\tvalidation_0-auc:0.85172\n",
      "[91]\tvalidation_0-auc:0.85235\n",
      "[92]\tvalidation_0-auc:0.85286\n",
      "[93]\tvalidation_0-auc:0.85337\n",
      "[94]\tvalidation_0-auc:0.85383\n",
      "[95]\tvalidation_0-auc:0.85460\n",
      "[96]\tvalidation_0-auc:0.85491\n",
      "[97]\tvalidation_0-auc:0.85521\n",
      "[98]\tvalidation_0-auc:0.85569\n",
      "[99]\tvalidation_0-auc:0.85580\n",
      "[100]\tvalidation_0-auc:0.85569\n",
      "[101]\tvalidation_0-auc:0.85649\n",
      "[102]\tvalidation_0-auc:0.85706\n",
      "[103]\tvalidation_0-auc:0.85757\n",
      "[104]\tvalidation_0-auc:0.85791\n",
      "[105]\tvalidation_0-auc:0.85822\n",
      "[106]\tvalidation_0-auc:0.85832\n",
      "[107]\tvalidation_0-auc:0.85863\n",
      "[108]\tvalidation_0-auc:0.85885\n",
      "[109]\tvalidation_0-auc:0.85900\n",
      "[110]\tvalidation_0-auc:0.85945\n",
      "[111]\tvalidation_0-auc:0.86013\n",
      "[112]\tvalidation_0-auc:0.86006\n",
      "[113]\tvalidation_0-auc:0.86044\n",
      "[114]\tvalidation_0-auc:0.86103\n",
      "[115]\tvalidation_0-auc:0.86146\n",
      "[116]\tvalidation_0-auc:0.86151\n",
      "[117]\tvalidation_0-auc:0.86195\n",
      "[118]\tvalidation_0-auc:0.86209\n",
      "[119]\tvalidation_0-auc:0.86263\n",
      "[120]\tvalidation_0-auc:0.86296\n",
      "[121]\tvalidation_0-auc:0.86304\n",
      "[122]\tvalidation_0-auc:0.86344\n",
      "[123]\tvalidation_0-auc:0.86352\n",
      "[124]\tvalidation_0-auc:0.86371\n",
      "[125]\tvalidation_0-auc:0.86413\n",
      "[126]\tvalidation_0-auc:0.86418\n",
      "[127]\tvalidation_0-auc:0.86472\n",
      "[128]\tvalidation_0-auc:0.86492\n",
      "[129]\tvalidation_0-auc:0.86526\n",
      "[130]\tvalidation_0-auc:0.86531\n",
      "[131]\tvalidation_0-auc:0.86561\n",
      "[132]\tvalidation_0-auc:0.86588\n",
      "[133]\tvalidation_0-auc:0.86624\n",
      "[134]\tvalidation_0-auc:0.86647\n",
      "[135]\tvalidation_0-auc:0.86661\n",
      "[136]\tvalidation_0-auc:0.86689\n",
      "[137]\tvalidation_0-auc:0.86693\n",
      "[138]\tvalidation_0-auc:0.86715\n",
      "[139]\tvalidation_0-auc:0.86727\n",
      "[140]\tvalidation_0-auc:0.86742\n",
      "[141]\tvalidation_0-auc:0.86777\n",
      "[142]\tvalidation_0-auc:0.86785\n",
      "[143]\tvalidation_0-auc:0.86793\n",
      "[144]\tvalidation_0-auc:0.86814\n",
      "[145]\tvalidation_0-auc:0.86853\n",
      "[146]\tvalidation_0-auc:0.86893\n",
      "[147]\tvalidation_0-auc:0.86936\n",
      "[148]\tvalidation_0-auc:0.86950\n",
      "[149]\tvalidation_0-auc:0.86965\n",
      "[150]\tvalidation_0-auc:0.86979\n",
      "[151]\tvalidation_0-auc:0.87004\n",
      "[152]\tvalidation_0-auc:0.87031\n",
      "[153]\tvalidation_0-auc:0.87071\n",
      "[154]\tvalidation_0-auc:0.87087\n",
      "[155]\tvalidation_0-auc:0.87116\n",
      "[156]\tvalidation_0-auc:0.87115\n",
      "[157]\tvalidation_0-auc:0.87146\n",
      "[158]\tvalidation_0-auc:0.87170\n",
      "[159]\tvalidation_0-auc:0.87185\n",
      "[160]\tvalidation_0-auc:0.87191\n",
      "[161]\tvalidation_0-auc:0.87204\n",
      "[162]\tvalidation_0-auc:0.87210\n",
      "[163]\tvalidation_0-auc:0.87213\n",
      "[164]\tvalidation_0-auc:0.87251\n",
      "[165]\tvalidation_0-auc:0.87264\n",
      "[166]\tvalidation_0-auc:0.87282\n",
      "[167]\tvalidation_0-auc:0.87306\n",
      "[168]\tvalidation_0-auc:0.87328\n",
      "[169]\tvalidation_0-auc:0.87349\n",
      "[170]\tvalidation_0-auc:0.87374\n",
      "[171]\tvalidation_0-auc:0.87392\n",
      "[172]\tvalidation_0-auc:0.87396\n",
      "[173]\tvalidation_0-auc:0.87413\n",
      "[174]\tvalidation_0-auc:0.87433\n",
      "[175]\tvalidation_0-auc:0.87449\n",
      "[176]\tvalidation_0-auc:0.87463\n",
      "[177]\tvalidation_0-auc:0.87480\n",
      "[178]\tvalidation_0-auc:0.87487\n",
      "[179]\tvalidation_0-auc:0.87501\n",
      "[180]\tvalidation_0-auc:0.87511\n",
      "[181]\tvalidation_0-auc:0.87529\n",
      "[182]\tvalidation_0-auc:0.87526\n",
      "[183]\tvalidation_0-auc:0.87546\n",
      "[184]\tvalidation_0-auc:0.87558\n",
      "[185]\tvalidation_0-auc:0.87574\n",
      "[186]\tvalidation_0-auc:0.87582\n",
      "[187]\tvalidation_0-auc:0.87587\n",
      "[188]\tvalidation_0-auc:0.87621\n",
      "[189]\tvalidation_0-auc:0.87643\n",
      "[190]\tvalidation_0-auc:0.87651\n",
      "[191]\tvalidation_0-auc:0.87636\n",
      "[192]\tvalidation_0-auc:0.87661\n",
      "[193]\tvalidation_0-auc:0.87674\n",
      "[194]\tvalidation_0-auc:0.87687\n",
      "[195]\tvalidation_0-auc:0.87690\n",
      "[196]\tvalidation_0-auc:0.87700\n",
      "[197]\tvalidation_0-auc:0.87716\n",
      "[198]\tvalidation_0-auc:0.87721\n",
      "[199]\tvalidation_0-auc:0.87727\n",
      "[200]\tvalidation_0-auc:0.87739\n",
      "[201]\tvalidation_0-auc:0.87753\n",
      "[202]\tvalidation_0-auc:0.87756\n",
      "[203]\tvalidation_0-auc:0.87770\n",
      "[204]\tvalidation_0-auc:0.87796\n",
      "[205]\tvalidation_0-auc:0.87799\n",
      "[206]\tvalidation_0-auc:0.87804\n",
      "[207]\tvalidation_0-auc:0.87819\n",
      "[208]\tvalidation_0-auc:0.87838\n",
      "[209]\tvalidation_0-auc:0.87854\n",
      "[210]\tvalidation_0-auc:0.87856\n",
      "[211]\tvalidation_0-auc:0.87859\n",
      "[212]\tvalidation_0-auc:0.87880\n",
      "[213]\tvalidation_0-auc:0.87856\n",
      "[214]\tvalidation_0-auc:0.87865\n",
      "[215]\tvalidation_0-auc:0.87874\n",
      "[216]\tvalidation_0-auc:0.87877\n",
      "[217]\tvalidation_0-auc:0.87900\n",
      "[218]\tvalidation_0-auc:0.87928\n",
      "[219]\tvalidation_0-auc:0.87951\n",
      "[220]\tvalidation_0-auc:0.87953\n",
      "[221]\tvalidation_0-auc:0.87965\n",
      "[222]\tvalidation_0-auc:0.87984\n",
      "[223]\tvalidation_0-auc:0.87998\n",
      "[224]\tvalidation_0-auc:0.88012\n",
      "[225]\tvalidation_0-auc:0.88047\n",
      "[226]\tvalidation_0-auc:0.88074\n",
      "[227]\tvalidation_0-auc:0.88092\n",
      "[228]\tvalidation_0-auc:0.88096\n",
      "[229]\tvalidation_0-auc:0.88106\n",
      "[230]\tvalidation_0-auc:0.88110\n",
      "[231]\tvalidation_0-auc:0.88120\n",
      "[232]\tvalidation_0-auc:0.88139\n",
      "[233]\tvalidation_0-auc:0.88136\n",
      "[234]\tvalidation_0-auc:0.88163\n",
      "[235]\tvalidation_0-auc:0.88162\n",
      "[236]\tvalidation_0-auc:0.88167\n",
      "[237]\tvalidation_0-auc:0.88179\n",
      "[238]\tvalidation_0-auc:0.88191\n",
      "[239]\tvalidation_0-auc:0.88193\n",
      "[240]\tvalidation_0-auc:0.88200\n",
      "[241]\tvalidation_0-auc:0.88200\n",
      "[242]\tvalidation_0-auc:0.88207\n",
      "[243]\tvalidation_0-auc:0.88209\n",
      "[244]\tvalidation_0-auc:0.88218\n",
      "[245]\tvalidation_0-auc:0.88230\n",
      "[246]\tvalidation_0-auc:0.88231\n",
      "[247]\tvalidation_0-auc:0.88254\n",
      "[248]\tvalidation_0-auc:0.88256\n",
      "[249]\tvalidation_0-auc:0.88261\n",
      "[250]\tvalidation_0-auc:0.88255\n",
      "[251]\tvalidation_0-auc:0.88253\n",
      "[252]\tvalidation_0-auc:0.88254\n",
      "[253]\tvalidation_0-auc:0.88269\n",
      "[254]\tvalidation_0-auc:0.88277\n",
      "[255]\tvalidation_0-auc:0.88286\n",
      "[256]\tvalidation_0-auc:0.88289\n",
      "[257]\tvalidation_0-auc:0.88317\n",
      "[258]\tvalidation_0-auc:0.88319\n",
      "[259]\tvalidation_0-auc:0.88323\n",
      "[260]\tvalidation_0-auc:0.88318\n",
      "[261]\tvalidation_0-auc:0.88321\n",
      "[262]\tvalidation_0-auc:0.88329\n",
      "[263]\tvalidation_0-auc:0.88330\n",
      "[264]\tvalidation_0-auc:0.88332\n",
      "[265]\tvalidation_0-auc:0.88340\n",
      "[266]\tvalidation_0-auc:0.88360\n",
      "[267]\tvalidation_0-auc:0.88363\n",
      "[268]\tvalidation_0-auc:0.88374\n",
      "[269]\tvalidation_0-auc:0.88383\n",
      "[270]\tvalidation_0-auc:0.88395\n",
      "[271]\tvalidation_0-auc:0.88401\n",
      "[272]\tvalidation_0-auc:0.88406\n",
      "[273]\tvalidation_0-auc:0.88423\n",
      "[274]\tvalidation_0-auc:0.88431\n",
      "[275]\tvalidation_0-auc:0.88444\n",
      "[276]\tvalidation_0-auc:0.88450\n",
      "[277]\tvalidation_0-auc:0.88455\n",
      "[278]\tvalidation_0-auc:0.88469\n",
      "[279]\tvalidation_0-auc:0.88482\n",
      "[280]\tvalidation_0-auc:0.88485\n",
      "[281]\tvalidation_0-auc:0.88492\n",
      "[282]\tvalidation_0-auc:0.88507\n",
      "[283]\tvalidation_0-auc:0.88507\n",
      "[284]\tvalidation_0-auc:0.88521\n",
      "[285]\tvalidation_0-auc:0.88530\n",
      "[286]\tvalidation_0-auc:0.88533\n",
      "[287]\tvalidation_0-auc:0.88546\n",
      "[288]\tvalidation_0-auc:0.88560\n",
      "[289]\tvalidation_0-auc:0.88559\n",
      "[290]\tvalidation_0-auc:0.88567\n",
      "[291]\tvalidation_0-auc:0.88577\n",
      "[292]\tvalidation_0-auc:0.88580\n",
      "[293]\tvalidation_0-auc:0.88590\n",
      "[294]\tvalidation_0-auc:0.88588\n",
      "[295]\tvalidation_0-auc:0.88608\n",
      "[296]\tvalidation_0-auc:0.88623\n",
      "[297]\tvalidation_0-auc:0.88635\n",
      "[298]\tvalidation_0-auc:0.88643\n",
      "[299]\tvalidation_0-auc:0.88643\n",
      "[300]\tvalidation_0-auc:0.88647\n",
      "[301]\tvalidation_0-auc:0.88649\n",
      "[302]\tvalidation_0-auc:0.88657\n",
      "[303]\tvalidation_0-auc:0.88666\n",
      "[304]\tvalidation_0-auc:0.88665\n",
      "[305]\tvalidation_0-auc:0.88667\n",
      "[306]\tvalidation_0-auc:0.88678\n",
      "[307]\tvalidation_0-auc:0.88672\n",
      "[308]\tvalidation_0-auc:0.88676\n",
      "[309]\tvalidation_0-auc:0.88678\n",
      "[310]\tvalidation_0-auc:0.88682\n",
      "[311]\tvalidation_0-auc:0.88680\n",
      "[312]\tvalidation_0-auc:0.88687\n",
      "[313]\tvalidation_0-auc:0.88696\n",
      "[314]\tvalidation_0-auc:0.88698\n",
      "[315]\tvalidation_0-auc:0.88698\n",
      "[316]\tvalidation_0-auc:0.88713\n",
      "[317]\tvalidation_0-auc:0.88719\n",
      "[318]\tvalidation_0-auc:0.88727\n",
      "[319]\tvalidation_0-auc:0.88724\n",
      "[320]\tvalidation_0-auc:0.88724\n",
      "[321]\tvalidation_0-auc:0.88736\n",
      "[322]\tvalidation_0-auc:0.88725\n",
      "[323]\tvalidation_0-auc:0.88728\n",
      "[324]\tvalidation_0-auc:0.88735\n",
      "[325]\tvalidation_0-auc:0.88734\n",
      "[326]\tvalidation_0-auc:0.88746\n",
      "[327]\tvalidation_0-auc:0.88752\n",
      "[328]\tvalidation_0-auc:0.88762\n",
      "[329]\tvalidation_0-auc:0.88763\n",
      "[330]\tvalidation_0-auc:0.88774\n",
      "[331]\tvalidation_0-auc:0.88769\n",
      "[332]\tvalidation_0-auc:0.88766\n",
      "[333]\tvalidation_0-auc:0.88775\n",
      "[334]\tvalidation_0-auc:0.88766\n",
      "[335]\tvalidation_0-auc:0.88775\n",
      "[336]\tvalidation_0-auc:0.88776\n",
      "[337]\tvalidation_0-auc:0.88777\n",
      "[338]\tvalidation_0-auc:0.88782\n",
      "[339]\tvalidation_0-auc:0.88780\n",
      "[340]\tvalidation_0-auc:0.88784\n",
      "[341]\tvalidation_0-auc:0.88798\n",
      "[342]\tvalidation_0-auc:0.88804\n",
      "[343]\tvalidation_0-auc:0.88811\n",
      "[344]\tvalidation_0-auc:0.88814\n",
      "[345]\tvalidation_0-auc:0.88823\n",
      "[346]\tvalidation_0-auc:0.88830\n",
      "[347]\tvalidation_0-auc:0.88822\n",
      "[348]\tvalidation_0-auc:0.88836\n",
      "[349]\tvalidation_0-auc:0.88837\n",
      "[350]\tvalidation_0-auc:0.88843\n",
      "[351]\tvalidation_0-auc:0.88840\n",
      "[352]\tvalidation_0-auc:0.88846\n",
      "[353]\tvalidation_0-auc:0.88851\n",
      "[354]\tvalidation_0-auc:0.88874\n",
      "[355]\tvalidation_0-auc:0.88876\n",
      "[356]\tvalidation_0-auc:0.88885\n",
      "[357]\tvalidation_0-auc:0.88886\n",
      "[358]\tvalidation_0-auc:0.88885\n",
      "[359]\tvalidation_0-auc:0.88886\n",
      "[360]\tvalidation_0-auc:0.88890\n",
      "[361]\tvalidation_0-auc:0.88894\n",
      "[362]\tvalidation_0-auc:0.88901\n",
      "[363]\tvalidation_0-auc:0.88900\n",
      "[364]\tvalidation_0-auc:0.88915\n",
      "[365]\tvalidation_0-auc:0.88915\n",
      "[366]\tvalidation_0-auc:0.88919\n",
      "[367]\tvalidation_0-auc:0.88919\n",
      "[368]\tvalidation_0-auc:0.88916\n",
      "[369]\tvalidation_0-auc:0.88911\n",
      "[370]\tvalidation_0-auc:0.88916\n",
      "[371]\tvalidation_0-auc:0.88926\n",
      "[372]\tvalidation_0-auc:0.88929\n",
      "[373]\tvalidation_0-auc:0.88946\n",
      "[374]\tvalidation_0-auc:0.88936\n",
      "[375]\tvalidation_0-auc:0.88946\n",
      "[376]\tvalidation_0-auc:0.88942\n",
      "[377]\tvalidation_0-auc:0.88944\n",
      "[378]\tvalidation_0-auc:0.88948\n",
      "[379]\tvalidation_0-auc:0.88941\n",
      "[380]\tvalidation_0-auc:0.88938\n",
      "[381]\tvalidation_0-auc:0.88927\n",
      "[382]\tvalidation_0-auc:0.88929\n",
      "[383]\tvalidation_0-auc:0.88923\n",
      "[384]\tvalidation_0-auc:0.88931\n",
      "[385]\tvalidation_0-auc:0.88933\n",
      "[386]\tvalidation_0-auc:0.88932\n",
      "[387]\tvalidation_0-auc:0.88940\n",
      "[388]\tvalidation_0-auc:0.88957\n",
      "[389]\tvalidation_0-auc:0.88956\n",
      "[390]\tvalidation_0-auc:0.88959\n",
      "[391]\tvalidation_0-auc:0.88959\n",
      "[392]\tvalidation_0-auc:0.88954\n",
      "[393]\tvalidation_0-auc:0.88968\n",
      "[394]\tvalidation_0-auc:0.88970\n",
      "[395]\tvalidation_0-auc:0.88975\n",
      "[396]\tvalidation_0-auc:0.88978\n",
      "[397]\tvalidation_0-auc:0.88980\n",
      "[398]\tvalidation_0-auc:0.88980\n",
      "[399]\tvalidation_0-auc:0.88985\n",
      "[400]\tvalidation_0-auc:0.88992\n",
      "[401]\tvalidation_0-auc:0.88991\n",
      "[402]\tvalidation_0-auc:0.88993\n",
      "[403]\tvalidation_0-auc:0.88991\n",
      "[404]\tvalidation_0-auc:0.88993\n",
      "[405]\tvalidation_0-auc:0.88999\n",
      "[406]\tvalidation_0-auc:0.89004\n",
      "[407]\tvalidation_0-auc:0.89006\n",
      "[408]\tvalidation_0-auc:0.89007\n",
      "[409]\tvalidation_0-auc:0.89009\n",
      "[410]\tvalidation_0-auc:0.89009\n",
      "[411]\tvalidation_0-auc:0.89009\n",
      "[412]\tvalidation_0-auc:0.89027\n",
      "[413]\tvalidation_0-auc:0.89025\n",
      "[414]\tvalidation_0-auc:0.89028\n",
      "[415]\tvalidation_0-auc:0.89037\n",
      "[416]\tvalidation_0-auc:0.89035\n",
      "[417]\tvalidation_0-auc:0.89044\n",
      "[418]\tvalidation_0-auc:0.89038\n",
      "[419]\tvalidation_0-auc:0.89051\n",
      "[420]\tvalidation_0-auc:0.89052\n",
      "[421]\tvalidation_0-auc:0.89047\n",
      "[422]\tvalidation_0-auc:0.89053\n",
      "[423]\tvalidation_0-auc:0.89055\n",
      "[424]\tvalidation_0-auc:0.89056\n",
      "[425]\tvalidation_0-auc:0.89052\n",
      "[426]\tvalidation_0-auc:0.89057\n",
      "[427]\tvalidation_0-auc:0.89064\n",
      "[428]\tvalidation_0-auc:0.89067\n",
      "[429]\tvalidation_0-auc:0.89073\n",
      "[430]\tvalidation_0-auc:0.89071\n",
      "[431]\tvalidation_0-auc:0.89072\n",
      "[432]\tvalidation_0-auc:0.89066\n",
      "[433]\tvalidation_0-auc:0.89070\n",
      "[434]\tvalidation_0-auc:0.89077\n",
      "[435]\tvalidation_0-auc:0.89065\n",
      "[436]\tvalidation_0-auc:0.89059\n",
      "[437]\tvalidation_0-auc:0.89051\n",
      "[438]\tvalidation_0-auc:0.89050\n",
      "[439]\tvalidation_0-auc:0.89055\n",
      "[440]\tvalidation_0-auc:0.89058\n",
      "[441]\tvalidation_0-auc:0.89077\n",
      "[442]\tvalidation_0-auc:0.89072\n",
      "[443]\tvalidation_0-auc:0.89068\n",
      "[444]\tvalidation_0-auc:0.89061\n",
      "[445]\tvalidation_0-auc:0.89061\n",
      "[446]\tvalidation_0-auc:0.89068\n",
      "[447]\tvalidation_0-auc:0.89076\n",
      "[448]\tvalidation_0-auc:0.89083\n",
      "[449]\tvalidation_0-auc:0.89090\n",
      "[450]\tvalidation_0-auc:0.89096\n",
      "[451]\tvalidation_0-auc:0.89090\n",
      "[452]\tvalidation_0-auc:0.89093\n",
      "[453]\tvalidation_0-auc:0.89090\n",
      "[454]\tvalidation_0-auc:0.89087\n",
      "[455]\tvalidation_0-auc:0.89091\n",
      "[456]\tvalidation_0-auc:0.89084\n",
      "[457]\tvalidation_0-auc:0.89096\n",
      "[458]\tvalidation_0-auc:0.89101\n",
      "[459]\tvalidation_0-auc:0.89097\n",
      "[460]\tvalidation_0-auc:0.89097\n",
      "[461]\tvalidation_0-auc:0.89104\n",
      "[462]\tvalidation_0-auc:0.89108\n",
      "[463]\tvalidation_0-auc:0.89109\n",
      "[464]\tvalidation_0-auc:0.89103\n",
      "[465]\tvalidation_0-auc:0.89099\n",
      "[466]\tvalidation_0-auc:0.89096\n",
      "[467]\tvalidation_0-auc:0.89090\n",
      "[468]\tvalidation_0-auc:0.89087\n",
      "[469]\tvalidation_0-auc:0.89087\n",
      "[470]\tvalidation_0-auc:0.89088\n",
      "[471]\tvalidation_0-auc:0.89086\n",
      "[472]\tvalidation_0-auc:0.89083\n",
      "[473]\tvalidation_0-auc:0.89077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=5000, n_jobs=12,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.5, tree_method='exact',\n",
       "              validate_parameters=1, verbosiry=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.fit(X_train,\n",
    "                  y_train,\n",
    "                  early_stopping_rounds=10,  # No new tree is built if model performance doesn't improve over 10 iterations\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d343ca-a192-4acb-8622-241ad9a1efb3",
   "metadata": {},
   "source": [
    "### 3. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a88f933-5b84-4056-9fd3-10af383d3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train: 0.9717\n",
      "AUC Valid: 0.8911\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = xgboost_model.predict_proba(X_train)[:,1]\n",
    "y_val_pred = xgboost_model.predict_proba(X_val)[:,1] \n",
    "\n",
    "print(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n",
    "                                                     roc_auc_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7a7e3-75bb-4e76-a765-b79f936402fd",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter tuning\n",
    "We will use GridSearchCV for hyperparameter tuning. First, let's define all the possible hyperparameter values which we want to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f46503-24ee-44a0-87ce-719449f3deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.02, 0.05, 0.1],\n",
       " 'max_depth': [2, 3, 5],\n",
       " 'n_estimators': [1000, 2000, 3000]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = [0.02, 0.05, 0.1]\n",
    "max_depth = [2, 3, 5]\n",
    "n_estimators = [1000, 2000, 3000]\n",
    "\n",
    "params_dict = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"n_estimators\": n_estimators\n",
    "}\n",
    "\n",
    "num_combinations = 1\n",
    "\n",
    "for val in params_dict.values(): \n",
    "    num_combinations *= len(val)\n",
    "    \n",
    "print(num_combinations)\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd72a70-be77-4695-8274-935bc445ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_roc_auc_score(model, X, y):\n",
    "    return roc_auc_score(y, model.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8053784d-7d62-42fb-95cd-06b7930a81ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=2, n_estimators=1000;, score=(train=0.882, test=0.860) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=2, n_estimators=1000;, score=(train=0.882, test=0.859) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=2, n_estimators=2000;, score=(train=0.908, test=0.883) total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=2, n_estimators=2000;, score=(train=0.910, test=0.882) total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=2, n_estimators=3000;, score=(train=0.920, test=0.892) total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=2, n_estimators=3000;, score=(train=0.922, test=0.891) total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=3, n_estimators=1000;, score=(train=0.912, test=0.876) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=3, n_estimators=1000;, score=(train=0.913, test=0.875) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=3, n_estimators=2000;, score=(train=0.937, test=0.893) total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=3, n_estimators=2000;, score=(train=0.939, test=0.892) total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=3, n_estimators=3000;, score=(train=0.949, test=0.899) total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=3, n_estimators=3000;, score=(train=0.951, test=0.897) total time= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=5, n_estimators=1000;, score=(train=0.966, test=0.888) total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=5, n_estimators=1000;, score=(train=0.967, test=0.888) total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=5, n_estimators=2000;, score=(train=0.987, test=0.898) total time= 5.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=5, n_estimators=2000;, score=(train=0.988, test=0.896) total time= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.02, max_depth=5, n_estimators=3000;, score=(train=0.995, test=0.899) total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.02, max_depth=5, n_estimators=3000;, score=(train=0.996, test=0.897) total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=2, n_estimators=1000;, score=(train=0.915, test=0.888) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=2, n_estimators=1000;, score=(train=0.916, test=0.885) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=2, n_estimators=2000;, score=(train=0.932, test=0.898) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=2, n_estimators=2000;, score=(train=0.934, test=0.896) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=2, n_estimators=3000;, score=(train=0.942, test=0.900) total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=2, n_estimators=3000;, score=(train=0.944, test=0.898) total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=(train=0.943, test=0.894) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=(train=0.944, test=0.894) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=3, n_estimators=2000;, score=(train=0.963, test=0.898) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=3, n_estimators=2000;, score=(train=0.965, test=0.898) total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=3, n_estimators=3000;, score=(train=0.977, test=0.898) total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=3, n_estimators=3000;, score=(train=0.978, test=0.898) total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=5, n_estimators=1000;, score=(train=0.991, test=0.894) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=5, n_estimators=1000;, score=(train=0.992, test=0.894) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=5, n_estimators=2000;, score=(train=1.000, test=0.894) total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=5, n_estimators=2000;, score=(train=1.000, test=0.893) total time= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.05, max_depth=5, n_estimators=3000;, score=(train=1.000, test=0.893) total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.05, max_depth=5, n_estimators=3000;, score=(train=1.000, test=0.893) total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.1, max_depth=2, n_estimators=1000;, score=(train=0.931, test=0.896) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.1, max_depth=2, n_estimators=1000;, score=(train=0.931, test=0.895) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.1, max_depth=2, n_estimators=2000;, score=(train=0.948, test=0.898) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.1, max_depth=2, n_estimators=2000;, score=(train=0.949, test=0.895) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.1, max_depth=2, n_estimators=3000;, score=(train=0.961, test=0.897) total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.1, max_depth=2, n_estimators=3000;, score=(train=0.962, test=0.894) total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=(train=0.961, test=0.896) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\LONAA32\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=(train=0.963, test=0.895) total time= 1.9min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21516/2784466574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                 verbose=4)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel_xgboost_hp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1497\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_xgboost_hp = GridSearchCV(estimator=xgboost.XGBClassifier(subsample=0.5,\n",
    "                                                                colsample_bytree=0.25,\n",
    "                                                                eval_metric=\"auc\",\n",
    "                                                                use_label_encoder=False),\n",
    "                                param_grid=params_dict,\n",
    "                                cv=2,\n",
    "                                scoring=my_roc_auc_score,\n",
    "                                return_train_score=True,\n",
    "                                verbose=4)\n",
    "\n",
    "model_xgboost_hp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8b29b-a327-4e51-834a-388407d0cfb3",
   "metadata": {},
   "source": [
    "Now let's look at the output of grid search by ranking by test score i.e. performance on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9513261-6a07-4f83-a4c1-b69065327aa2",
   "metadata": {},
   "source": [
    "### 5. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0311dff-5c2d-4bf4-9f21-6bb8a8e59c70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'cv_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15280/3307814939.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_cv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m df_cv_results = df_cv_results[[\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'rank_test_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'mean_train_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'cv_results'"
     ]
    }
   ],
   "source": [
    "df_cv_results = pd.DataFrame(model_xgboost_hp.cv_results)\n",
    "df_cv_results = df_cv_results[[\n",
    "    'rank_test_score',\n",
    "    'mean_test_score',\n",
    "    'mean_train_score',\n",
    "    'param_learning_rate',\n",
    "    'param_max_depth',\n",
    "    'param_n_estimators'\n",
    "]]\n",
    "\n",
    "df_cv_results.sort_values(by='rank_test_score', inplace=True, ignore_index=True)\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a350d4-0e85-4bf1-80b5-68cb7c0d417b",
   "metadata": {},
   "source": [
    "### 6. Build final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ef7f00-20a7-4d3a-9c6f-97928b8b676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = xgboost.XGBClassifier(learning_rate=0.1,\n",
    "                                      max_depth=5,\n",
    "                                      n_estimators=5000,\n",
    "                                      subsample=0.5,\n",
    "                                      colsample_bytree=0.5,\n",
    "                                      eval_metric='auc',\n",
    "                                      verbosiry=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21a488e-a10e-4ae0-92af-78eb700cda90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'validation_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15280/2446617697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Index into each key to find AUC values for training and validation data after each tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_auc_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvalid_auc_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'validation_1'"
     ]
    }
   ],
   "source": [
    "evaluation_results = xgboost_model.evals_result()\n",
    "\n",
    "# Index into each key to find AUC values for training and validation data after each tree\n",
    "train_auc_tree = evaluation_results['validation_0']['auc']\n",
    "valid_auc_tree = evaluation_results['validation_1']['auc']\n",
    "\n",
    "\n",
    "# Plotting Section\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(train_auc_tree, label='Train')\n",
    "plt.plot(valid_auc_tree, label='valid')\n",
    "\n",
    "plt.title(\"Train and validation AUC as number of trees increase\")\n",
    "plt.xlabel(\"Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c6d42-8404-46de-87fd-9153aee27ebd",
   "metadata": {},
   "source": [
    "Let us also look at variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816bf7a-37df-40a3-ba88-8691eb04acb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_var_imp = pd.DataFrame({\"Variable\": var_colums,\n",
    "                           \"Importance\": xgboost_model.feature_importances_}) \\\n",
    "                        .sort_values(by='Importance', ascending=False)\n",
    "df_var_imp[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803dad0-8231-48b4-8daa-f3a7f1b23cbb",
   "metadata": {},
   "source": [
    "### 7. Score the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e867712-bf0b-4974-a07f-ff638d2da3f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ID_code'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15280/4000096568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ID_code'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4899\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4900\u001b[0m         \"\"\"\n\u001b[1;32m-> 4901\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4902\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4903\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ID_code'] not found in axis\""
     ]
    }
   ],
   "source": [
    "test.drop('ID_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "317509af-5d3d-428f-acee-fef20aa39a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = xgboost_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235176c-0248-450f-b4c1-cedff69d6555",
   "metadata": {},
   "source": [
    "### A. Model Training - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e216f-1b95-48cd-8ada-5866344d2efa",
   "metadata": {},
   "source": [
    "Specify parameters of LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f46ced53-3290-4c86-8b1c-5ff55d5a1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d37871-75ae-4379-92e4-8c819d9bce16",
   "metadata": {},
   "source": [
    "Train the LightGBM model for maximum 5000 rounds. Early stopping criteria is 50 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40710317-dbab-4fec-b6dc-e0ec9c397b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lightgbm.Dataset(X_train, label=y_train)\n",
    "valid_data = lightgbm.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6965dfb5-9e6a-4b2c-9eb8-1e2120f4d3c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.655092\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.678622\n",
      "[3]\tvalid_0's auc: 0.704128\n",
      "[4]\tvalid_0's auc: 0.728007\n",
      "[5]\tvalid_0's auc: 0.737301\n",
      "[6]\tvalid_0's auc: 0.74417\n",
      "[7]\tvalid_0's auc: 0.75175\n",
      "[8]\tvalid_0's auc: 0.754857\n",
      "[9]\tvalid_0's auc: 0.756272\n",
      "[10]\tvalid_0's auc: 0.760885\n",
      "[11]\tvalid_0's auc: 0.762652\n",
      "[12]\tvalid_0's auc: 0.764331\n",
      "[13]\tvalid_0's auc: 0.767547\n",
      "[14]\tvalid_0's auc: 0.769745\n",
      "[15]\tvalid_0's auc: 0.770371\n",
      "[16]\tvalid_0's auc: 0.769788\n",
      "[17]\tvalid_0's auc: 0.769871\n",
      "[18]\tvalid_0's auc: 0.77338\n",
      "[19]\tvalid_0's auc: 0.774528\n",
      "[20]\tvalid_0's auc: 0.778478\n",
      "[21]\tvalid_0's auc: 0.778934\n",
      "[22]\tvalid_0's auc: 0.78089\n",
      "[23]\tvalid_0's auc: 0.783205\n",
      "[24]\tvalid_0's auc: 0.785852\n",
      "[25]\tvalid_0's auc: 0.786899\n",
      "[26]\tvalid_0's auc: 0.788898\n",
      "[27]\tvalid_0's auc: 0.790423\n",
      "[28]\tvalid_0's auc: 0.792412\n",
      "[29]\tvalid_0's auc: 0.794326\n",
      "[30]\tvalid_0's auc: 0.795261\n",
      "[31]\tvalid_0's auc: 0.796949\n",
      "[32]\tvalid_0's auc: 0.797934\n",
      "[33]\tvalid_0's auc: 0.798444\n",
      "[34]\tvalid_0's auc: 0.799784\n",
      "[35]\tvalid_0's auc: 0.800334\n",
      "[36]\tvalid_0's auc: 0.800491\n",
      "[37]\tvalid_0's auc: 0.801521\n",
      "[38]\tvalid_0's auc: 0.802104\n",
      "[39]\tvalid_0's auc: 0.802585\n",
      "[40]\tvalid_0's auc: 0.803084\n",
      "[41]\tvalid_0's auc: 0.803991\n",
      "[42]\tvalid_0's auc: 0.804649\n",
      "[43]\tvalid_0's auc: 0.804654\n",
      "[44]\tvalid_0's auc: 0.805051\n",
      "[45]\tvalid_0's auc: 0.805112\n",
      "[46]\tvalid_0's auc: 0.806306\n",
      "[47]\tvalid_0's auc: 0.80709\n",
      "[48]\tvalid_0's auc: 0.807316\n",
      "[49]\tvalid_0's auc: 0.807693\n",
      "[50]\tvalid_0's auc: 0.808161\n",
      "[51]\tvalid_0's auc: 0.808252\n",
      "[52]\tvalid_0's auc: 0.809425\n",
      "[53]\tvalid_0's auc: 0.809765\n",
      "[54]\tvalid_0's auc: 0.809963\n",
      "[55]\tvalid_0's auc: 0.810016\n",
      "[56]\tvalid_0's auc: 0.810314\n",
      "[57]\tvalid_0's auc: 0.810831\n",
      "[58]\tvalid_0's auc: 0.81146\n",
      "[59]\tvalid_0's auc: 0.812605\n",
      "[60]\tvalid_0's auc: 0.81276\n",
      "[61]\tvalid_0's auc: 0.813416\n",
      "[62]\tvalid_0's auc: 0.81388\n",
      "[63]\tvalid_0's auc: 0.81392\n",
      "[64]\tvalid_0's auc: 0.814786\n",
      "[65]\tvalid_0's auc: 0.815239\n",
      "[66]\tvalid_0's auc: 0.815601\n",
      "[67]\tvalid_0's auc: 0.816113\n",
      "[68]\tvalid_0's auc: 0.816002\n",
      "[69]\tvalid_0's auc: 0.816269\n",
      "[70]\tvalid_0's auc: 0.816636\n",
      "[71]\tvalid_0's auc: 0.817387\n",
      "[72]\tvalid_0's auc: 0.817925\n",
      "[73]\tvalid_0's auc: 0.818088\n",
      "[74]\tvalid_0's auc: 0.81831\n",
      "[75]\tvalid_0's auc: 0.818475\n",
      "[76]\tvalid_0's auc: 0.81854\n",
      "[77]\tvalid_0's auc: 0.818961\n",
      "[78]\tvalid_0's auc: 0.819383\n",
      "[79]\tvalid_0's auc: 0.81997\n",
      "[80]\tvalid_0's auc: 0.82014\n",
      "[81]\tvalid_0's auc: 0.820599\n",
      "[82]\tvalid_0's auc: 0.820971\n",
      "[83]\tvalid_0's auc: 0.821324\n",
      "[84]\tvalid_0's auc: 0.821616\n",
      "[85]\tvalid_0's auc: 0.821832\n",
      "[86]\tvalid_0's auc: 0.822284\n",
      "[87]\tvalid_0's auc: 0.822565\n",
      "[88]\tvalid_0's auc: 0.822985\n",
      "[89]\tvalid_0's auc: 0.823347\n",
      "[90]\tvalid_0's auc: 0.823394\n",
      "[91]\tvalid_0's auc: 0.823748\n",
      "[92]\tvalid_0's auc: 0.824269\n",
      "[93]\tvalid_0's auc: 0.82426\n",
      "[94]\tvalid_0's auc: 0.824535\n",
      "[95]\tvalid_0's auc: 0.825004\n",
      "[96]\tvalid_0's auc: 0.825329\n",
      "[97]\tvalid_0's auc: 0.825615\n",
      "[98]\tvalid_0's auc: 0.825606\n",
      "[99]\tvalid_0's auc: 0.825847\n",
      "[100]\tvalid_0's auc: 0.825951\n",
      "[101]\tvalid_0's auc: 0.826597\n",
      "[102]\tvalid_0's auc: 0.826978\n",
      "[103]\tvalid_0's auc: 0.827253\n",
      "[104]\tvalid_0's auc: 0.827425\n",
      "[105]\tvalid_0's auc: 0.827594\n",
      "[106]\tvalid_0's auc: 0.827774\n",
      "[107]\tvalid_0's auc: 0.828193\n",
      "[108]\tvalid_0's auc: 0.82827\n",
      "[109]\tvalid_0's auc: 0.828882\n",
      "[110]\tvalid_0's auc: 0.828958\n",
      "[111]\tvalid_0's auc: 0.829072\n",
      "[112]\tvalid_0's auc: 0.829374\n",
      "[113]\tvalid_0's auc: 0.829733\n",
      "[114]\tvalid_0's auc: 0.830016\n",
      "[115]\tvalid_0's auc: 0.830453\n",
      "[116]\tvalid_0's auc: 0.830836\n",
      "[117]\tvalid_0's auc: 0.83109\n",
      "[118]\tvalid_0's auc: 0.831373\n",
      "[119]\tvalid_0's auc: 0.831779\n",
      "[120]\tvalid_0's auc: 0.832206\n",
      "[121]\tvalid_0's auc: 0.83225\n",
      "[122]\tvalid_0's auc: 0.83255\n",
      "[123]\tvalid_0's auc: 0.832591\n",
      "[124]\tvalid_0's auc: 0.832661\n",
      "[125]\tvalid_0's auc: 0.832792\n",
      "[126]\tvalid_0's auc: 0.832809\n",
      "[127]\tvalid_0's auc: 0.833119\n",
      "[128]\tvalid_0's auc: 0.833236\n",
      "[129]\tvalid_0's auc: 0.833343\n",
      "[130]\tvalid_0's auc: 0.833442\n",
      "[131]\tvalid_0's auc: 0.83365\n",
      "[132]\tvalid_0's auc: 0.833847\n",
      "[133]\tvalid_0's auc: 0.834052\n",
      "[134]\tvalid_0's auc: 0.834132\n",
      "[135]\tvalid_0's auc: 0.834562\n",
      "[136]\tvalid_0's auc: 0.834704\n",
      "[137]\tvalid_0's auc: 0.83489\n",
      "[138]\tvalid_0's auc: 0.835294\n",
      "[139]\tvalid_0's auc: 0.835325\n",
      "[140]\tvalid_0's auc: 0.835334\n",
      "[141]\tvalid_0's auc: 0.835466\n",
      "[142]\tvalid_0's auc: 0.835559\n",
      "[143]\tvalid_0's auc: 0.835717\n",
      "[144]\tvalid_0's auc: 0.836163\n",
      "[145]\tvalid_0's auc: 0.836273\n",
      "[146]\tvalid_0's auc: 0.836547\n",
      "[147]\tvalid_0's auc: 0.836729\n",
      "[148]\tvalid_0's auc: 0.836838\n",
      "[149]\tvalid_0's auc: 0.837068\n",
      "[150]\tvalid_0's auc: 0.837216\n",
      "[151]\tvalid_0's auc: 0.837447\n",
      "[152]\tvalid_0's auc: 0.837773\n",
      "[153]\tvalid_0's auc: 0.837803\n",
      "[154]\tvalid_0's auc: 0.837926\n",
      "[155]\tvalid_0's auc: 0.838087\n",
      "[156]\tvalid_0's auc: 0.838218\n",
      "[157]\tvalid_0's auc: 0.838352\n",
      "[158]\tvalid_0's auc: 0.838462\n",
      "[159]\tvalid_0's auc: 0.838518\n",
      "[160]\tvalid_0's auc: 0.838677\n",
      "[161]\tvalid_0's auc: 0.838932\n",
      "[162]\tvalid_0's auc: 0.839256\n",
      "[163]\tvalid_0's auc: 0.839384\n",
      "[164]\tvalid_0's auc: 0.839597\n",
      "[165]\tvalid_0's auc: 0.839676\n",
      "[166]\tvalid_0's auc: 0.839922\n",
      "[167]\tvalid_0's auc: 0.839971\n",
      "[168]\tvalid_0's auc: 0.840232\n",
      "[169]\tvalid_0's auc: 0.840175\n",
      "[170]\tvalid_0's auc: 0.840251\n",
      "[171]\tvalid_0's auc: 0.840282\n",
      "[172]\tvalid_0's auc: 0.840276\n",
      "[173]\tvalid_0's auc: 0.840469\n",
      "[174]\tvalid_0's auc: 0.840659\n",
      "[175]\tvalid_0's auc: 0.840877\n",
      "[176]\tvalid_0's auc: 0.84098\n",
      "[177]\tvalid_0's auc: 0.841085\n",
      "[178]\tvalid_0's auc: 0.841274\n",
      "[179]\tvalid_0's auc: 0.841433\n",
      "[180]\tvalid_0's auc: 0.84155\n",
      "[181]\tvalid_0's auc: 0.841874\n",
      "[182]\tvalid_0's auc: 0.842077\n",
      "[183]\tvalid_0's auc: 0.842366\n",
      "[184]\tvalid_0's auc: 0.842513\n",
      "[185]\tvalid_0's auc: 0.842645\n",
      "[186]\tvalid_0's auc: 0.842787\n",
      "[187]\tvalid_0's auc: 0.842984\n",
      "[188]\tvalid_0's auc: 0.843194\n",
      "[189]\tvalid_0's auc: 0.843448\n",
      "[190]\tvalid_0's auc: 0.843601\n",
      "[191]\tvalid_0's auc: 0.84373\n",
      "[192]\tvalid_0's auc: 0.843847\n",
      "[193]\tvalid_0's auc: 0.844019\n",
      "[194]\tvalid_0's auc: 0.844243\n",
      "[195]\tvalid_0's auc: 0.844407\n",
      "[196]\tvalid_0's auc: 0.844541\n",
      "[197]\tvalid_0's auc: 0.844642\n",
      "[198]\tvalid_0's auc: 0.844771\n",
      "[199]\tvalid_0's auc: 0.845026\n",
      "[200]\tvalid_0's auc: 0.845103\n",
      "[201]\tvalid_0's auc: 0.845283\n",
      "[202]\tvalid_0's auc: 0.845443\n",
      "[203]\tvalid_0's auc: 0.845584\n",
      "[204]\tvalid_0's auc: 0.845722\n",
      "[205]\tvalid_0's auc: 0.845917\n",
      "[206]\tvalid_0's auc: 0.846082\n",
      "[207]\tvalid_0's auc: 0.846253\n",
      "[208]\tvalid_0's auc: 0.846415\n",
      "[209]\tvalid_0's auc: 0.846578\n",
      "[210]\tvalid_0's auc: 0.846716\n",
      "[211]\tvalid_0's auc: 0.846833\n",
      "[212]\tvalid_0's auc: 0.846985\n",
      "[213]\tvalid_0's auc: 0.847034\n",
      "[214]\tvalid_0's auc: 0.847055\n",
      "[215]\tvalid_0's auc: 0.847198\n",
      "[216]\tvalid_0's auc: 0.847368\n",
      "[217]\tvalid_0's auc: 0.84747\n",
      "[218]\tvalid_0's auc: 0.847501\n",
      "[219]\tvalid_0's auc: 0.847656\n",
      "[220]\tvalid_0's auc: 0.847722\n",
      "[221]\tvalid_0's auc: 0.847766\n",
      "[222]\tvalid_0's auc: 0.847899\n",
      "[223]\tvalid_0's auc: 0.848001\n",
      "[224]\tvalid_0's auc: 0.848165\n",
      "[225]\tvalid_0's auc: 0.848341\n",
      "[226]\tvalid_0's auc: 0.848458\n",
      "[227]\tvalid_0's auc: 0.848591\n",
      "[228]\tvalid_0's auc: 0.848791\n",
      "[229]\tvalid_0's auc: 0.848946\n",
      "[230]\tvalid_0's auc: 0.849063\n",
      "[231]\tvalid_0's auc: 0.849134\n",
      "[232]\tvalid_0's auc: 0.849286\n",
      "[233]\tvalid_0's auc: 0.849363\n",
      "[234]\tvalid_0's auc: 0.849478\n",
      "[235]\tvalid_0's auc: 0.849566\n",
      "[236]\tvalid_0's auc: 0.849678\n",
      "[237]\tvalid_0's auc: 0.849695\n",
      "[238]\tvalid_0's auc: 0.84981\n",
      "[239]\tvalid_0's auc: 0.84998\n",
      "[240]\tvalid_0's auc: 0.850052\n",
      "[241]\tvalid_0's auc: 0.85024\n",
      "[242]\tvalid_0's auc: 0.85032\n",
      "[243]\tvalid_0's auc: 0.850396\n",
      "[244]\tvalid_0's auc: 0.850505\n",
      "[245]\tvalid_0's auc: 0.850559\n",
      "[246]\tvalid_0's auc: 0.850693\n",
      "[247]\tvalid_0's auc: 0.850814\n",
      "[248]\tvalid_0's auc: 0.850961\n",
      "[249]\tvalid_0's auc: 0.851127\n",
      "[250]\tvalid_0's auc: 0.85132\n",
      "[251]\tvalid_0's auc: 0.851399\n",
      "[252]\tvalid_0's auc: 0.851479\n",
      "[253]\tvalid_0's auc: 0.8516\n",
      "[254]\tvalid_0's auc: 0.851842\n",
      "[255]\tvalid_0's auc: 0.851891\n",
      "[256]\tvalid_0's auc: 0.852056\n",
      "[257]\tvalid_0's auc: 0.852156\n",
      "[258]\tvalid_0's auc: 0.852359\n",
      "[259]\tvalid_0's auc: 0.85239\n",
      "[260]\tvalid_0's auc: 0.85251\n",
      "[261]\tvalid_0's auc: 0.852582\n",
      "[262]\tvalid_0's auc: 0.852651\n",
      "[263]\tvalid_0's auc: 0.852726\n",
      "[264]\tvalid_0's auc: 0.85274\n",
      "[265]\tvalid_0's auc: 0.85282\n",
      "[266]\tvalid_0's auc: 0.852979\n",
      "[267]\tvalid_0's auc: 0.853094\n",
      "[268]\tvalid_0's auc: 0.853256\n",
      "[269]\tvalid_0's auc: 0.853352\n",
      "[270]\tvalid_0's auc: 0.853399\n",
      "[271]\tvalid_0's auc: 0.853523\n",
      "[272]\tvalid_0's auc: 0.853632\n",
      "[273]\tvalid_0's auc: 0.853756\n",
      "[274]\tvalid_0's auc: 0.853726\n",
      "[275]\tvalid_0's auc: 0.853879\n",
      "[276]\tvalid_0's auc: 0.853955\n",
      "[277]\tvalid_0's auc: 0.854046\n",
      "[278]\tvalid_0's auc: 0.854014\n",
      "[279]\tvalid_0's auc: 0.85413\n",
      "[280]\tvalid_0's auc: 0.854217\n",
      "[281]\tvalid_0's auc: 0.854353\n",
      "[282]\tvalid_0's auc: 0.85444\n",
      "[283]\tvalid_0's auc: 0.854585\n",
      "[284]\tvalid_0's auc: 0.854755\n",
      "[285]\tvalid_0's auc: 0.854867\n",
      "[286]\tvalid_0's auc: 0.855019\n",
      "[287]\tvalid_0's auc: 0.855155\n",
      "[288]\tvalid_0's auc: 0.855254\n",
      "[289]\tvalid_0's auc: 0.855397\n",
      "[290]\tvalid_0's auc: 0.855456\n",
      "[291]\tvalid_0's auc: 0.855537\n",
      "[292]\tvalid_0's auc: 0.855699\n",
      "[293]\tvalid_0's auc: 0.855802\n",
      "[294]\tvalid_0's auc: 0.855923\n",
      "[295]\tvalid_0's auc: 0.856058\n",
      "[296]\tvalid_0's auc: 0.856154\n",
      "[297]\tvalid_0's auc: 0.856312\n",
      "[298]\tvalid_0's auc: 0.856421\n",
      "[299]\tvalid_0's auc: 0.8565\n",
      "[300]\tvalid_0's auc: 0.856569\n",
      "[301]\tvalid_0's auc: 0.856662\n",
      "[302]\tvalid_0's auc: 0.856789\n",
      "[303]\tvalid_0's auc: 0.856837\n",
      "[304]\tvalid_0's auc: 0.856932\n",
      "[305]\tvalid_0's auc: 0.857007\n",
      "[306]\tvalid_0's auc: 0.857103\n",
      "[307]\tvalid_0's auc: 0.857173\n",
      "[308]\tvalid_0's auc: 0.857244\n",
      "[309]\tvalid_0's auc: 0.857338\n",
      "[310]\tvalid_0's auc: 0.857457\n",
      "[311]\tvalid_0's auc: 0.857641\n",
      "[312]\tvalid_0's auc: 0.857711\n",
      "[313]\tvalid_0's auc: 0.857785\n",
      "[314]\tvalid_0's auc: 0.85789\n",
      "[315]\tvalid_0's auc: 0.857903\n",
      "[316]\tvalid_0's auc: 0.858021\n",
      "[317]\tvalid_0's auc: 0.858145\n",
      "[318]\tvalid_0's auc: 0.858267\n",
      "[319]\tvalid_0's auc: 0.858381\n",
      "[320]\tvalid_0's auc: 0.858439\n",
      "[321]\tvalid_0's auc: 0.858514\n",
      "[322]\tvalid_0's auc: 0.858665\n",
      "[323]\tvalid_0's auc: 0.858744\n",
      "[324]\tvalid_0's auc: 0.858848\n",
      "[325]\tvalid_0's auc: 0.858929\n",
      "[326]\tvalid_0's auc: 0.858998\n",
      "[327]\tvalid_0's auc: 0.859181\n",
      "[328]\tvalid_0's auc: 0.85927\n",
      "[329]\tvalid_0's auc: 0.859365\n",
      "[330]\tvalid_0's auc: 0.859424\n",
      "[331]\tvalid_0's auc: 0.859511\n",
      "[332]\tvalid_0's auc: 0.859552\n",
      "[333]\tvalid_0's auc: 0.859713\n",
      "[334]\tvalid_0's auc: 0.859771\n",
      "[335]\tvalid_0's auc: 0.859861\n",
      "[336]\tvalid_0's auc: 0.859944\n",
      "[337]\tvalid_0's auc: 0.860034\n",
      "[338]\tvalid_0's auc: 0.860162\n",
      "[339]\tvalid_0's auc: 0.860281\n",
      "[340]\tvalid_0's auc: 0.860415\n",
      "[341]\tvalid_0's auc: 0.860499\n",
      "[342]\tvalid_0's auc: 0.86053\n",
      "[343]\tvalid_0's auc: 0.860668\n",
      "[344]\tvalid_0's auc: 0.86082\n",
      "[345]\tvalid_0's auc: 0.860916\n",
      "[346]\tvalid_0's auc: 0.860946\n",
      "[347]\tvalid_0's auc: 0.861015\n",
      "[348]\tvalid_0's auc: 0.861101\n",
      "[349]\tvalid_0's auc: 0.861206\n",
      "[350]\tvalid_0's auc: 0.861316\n",
      "[351]\tvalid_0's auc: 0.861384\n",
      "[352]\tvalid_0's auc: 0.861439\n",
      "[353]\tvalid_0's auc: 0.861435\n",
      "[354]\tvalid_0's auc: 0.861545\n",
      "[355]\tvalid_0's auc: 0.861577\n",
      "[356]\tvalid_0's auc: 0.86163\n",
      "[357]\tvalid_0's auc: 0.861736\n",
      "[358]\tvalid_0's auc: 0.86183\n",
      "[359]\tvalid_0's auc: 0.861847\n",
      "[360]\tvalid_0's auc: 0.861837\n",
      "[361]\tvalid_0's auc: 0.861944\n",
      "[362]\tvalid_0's auc: 0.862026\n",
      "[363]\tvalid_0's auc: 0.862154\n",
      "[364]\tvalid_0's auc: 0.86224\n",
      "[365]\tvalid_0's auc: 0.86239\n",
      "[366]\tvalid_0's auc: 0.862466\n",
      "[367]\tvalid_0's auc: 0.862482\n",
      "[368]\tvalid_0's auc: 0.862615\n",
      "[369]\tvalid_0's auc: 0.862736\n",
      "[370]\tvalid_0's auc: 0.862863\n",
      "[371]\tvalid_0's auc: 0.862998\n",
      "[372]\tvalid_0's auc: 0.863087\n",
      "[373]\tvalid_0's auc: 0.86314\n",
      "[374]\tvalid_0's auc: 0.863229\n",
      "[375]\tvalid_0's auc: 0.863237\n",
      "[376]\tvalid_0's auc: 0.863266\n",
      "[377]\tvalid_0's auc: 0.863358\n",
      "[378]\tvalid_0's auc: 0.863447\n",
      "[379]\tvalid_0's auc: 0.863533\n",
      "[380]\tvalid_0's auc: 0.86363\n",
      "[381]\tvalid_0's auc: 0.86376\n",
      "[382]\tvalid_0's auc: 0.863822\n",
      "[383]\tvalid_0's auc: 0.863863\n",
      "[384]\tvalid_0's auc: 0.86398\n",
      "[385]\tvalid_0's auc: 0.864072\n",
      "[386]\tvalid_0's auc: 0.864247\n",
      "[387]\tvalid_0's auc: 0.864365\n",
      "[388]\tvalid_0's auc: 0.864434\n",
      "[389]\tvalid_0's auc: 0.86456\n",
      "[390]\tvalid_0's auc: 0.864627\n",
      "[391]\tvalid_0's auc: 0.864708\n",
      "[392]\tvalid_0's auc: 0.864839\n",
      "[393]\tvalid_0's auc: 0.864884\n",
      "[394]\tvalid_0's auc: 0.864958\n",
      "[395]\tvalid_0's auc: 0.865007\n",
      "[396]\tvalid_0's auc: 0.865099\n",
      "[397]\tvalid_0's auc: 0.86522\n",
      "[398]\tvalid_0's auc: 0.86527\n",
      "[399]\tvalid_0's auc: 0.865349\n",
      "[400]\tvalid_0's auc: 0.865459\n",
      "[401]\tvalid_0's auc: 0.865538\n",
      "[402]\tvalid_0's auc: 0.865694\n",
      "[403]\tvalid_0's auc: 0.865736\n",
      "[404]\tvalid_0's auc: 0.865862\n",
      "[405]\tvalid_0's auc: 0.865943\n",
      "[406]\tvalid_0's auc: 0.865985\n",
      "[407]\tvalid_0's auc: 0.86607\n",
      "[408]\tvalid_0's auc: 0.866121\n",
      "[409]\tvalid_0's auc: 0.866167\n",
      "[410]\tvalid_0's auc: 0.866223\n",
      "[411]\tvalid_0's auc: 0.866279\n",
      "[412]\tvalid_0's auc: 0.866369\n",
      "[413]\tvalid_0's auc: 0.866435\n",
      "[414]\tvalid_0's auc: 0.866552\n",
      "[415]\tvalid_0's auc: 0.866619\n",
      "[416]\tvalid_0's auc: 0.866751\n",
      "[417]\tvalid_0's auc: 0.866809\n",
      "[418]\tvalid_0's auc: 0.866896\n",
      "[419]\tvalid_0's auc: 0.866979\n",
      "[420]\tvalid_0's auc: 0.867046\n",
      "[421]\tvalid_0's auc: 0.867152\n",
      "[422]\tvalid_0's auc: 0.867231\n",
      "[423]\tvalid_0's auc: 0.867303\n",
      "[424]\tvalid_0's auc: 0.867314\n",
      "[425]\tvalid_0's auc: 0.867395\n",
      "[426]\tvalid_0's auc: 0.867447\n",
      "[427]\tvalid_0's auc: 0.867515\n",
      "[428]\tvalid_0's auc: 0.867526\n",
      "[429]\tvalid_0's auc: 0.867591\n",
      "[430]\tvalid_0's auc: 0.867658\n",
      "[431]\tvalid_0's auc: 0.867729\n",
      "[432]\tvalid_0's auc: 0.867809\n",
      "[433]\tvalid_0's auc: 0.867875\n",
      "[434]\tvalid_0's auc: 0.867987\n",
      "[435]\tvalid_0's auc: 0.868034\n",
      "[436]\tvalid_0's auc: 0.868069\n",
      "[437]\tvalid_0's auc: 0.868113\n",
      "[438]\tvalid_0's auc: 0.868125\n",
      "[439]\tvalid_0's auc: 0.868117\n",
      "[440]\tvalid_0's auc: 0.868146\n",
      "[441]\tvalid_0's auc: 0.868299\n",
      "[442]\tvalid_0's auc: 0.868435\n",
      "[443]\tvalid_0's auc: 0.868489\n",
      "[444]\tvalid_0's auc: 0.868562\n",
      "[445]\tvalid_0's auc: 0.868642\n",
      "[446]\tvalid_0's auc: 0.868745\n",
      "[447]\tvalid_0's auc: 0.86876\n",
      "[448]\tvalid_0's auc: 0.868773\n",
      "[449]\tvalid_0's auc: 0.86883\n",
      "[450]\tvalid_0's auc: 0.868858\n",
      "[451]\tvalid_0's auc: 0.868906\n",
      "[452]\tvalid_0's auc: 0.868986\n",
      "[453]\tvalid_0's auc: 0.869001\n",
      "[454]\tvalid_0's auc: 0.869066\n",
      "[455]\tvalid_0's auc: 0.869177\n",
      "[456]\tvalid_0's auc: 0.869214\n",
      "[457]\tvalid_0's auc: 0.869341\n",
      "[458]\tvalid_0's auc: 0.869389\n",
      "[459]\tvalid_0's auc: 0.869472\n",
      "[460]\tvalid_0's auc: 0.869545\n",
      "[461]\tvalid_0's auc: 0.869634\n",
      "[462]\tvalid_0's auc: 0.869668\n",
      "[463]\tvalid_0's auc: 0.869775\n",
      "[464]\tvalid_0's auc: 0.86992\n",
      "[465]\tvalid_0's auc: 0.869953\n",
      "[466]\tvalid_0's auc: 0.870018\n",
      "[467]\tvalid_0's auc: 0.870124\n",
      "[468]\tvalid_0's auc: 0.870201\n",
      "[469]\tvalid_0's auc: 0.870207\n",
      "[470]\tvalid_0's auc: 0.87024\n",
      "[471]\tvalid_0's auc: 0.87026\n",
      "[472]\tvalid_0's auc: 0.870334\n",
      "[473]\tvalid_0's auc: 0.870368\n",
      "[474]\tvalid_0's auc: 0.870408\n",
      "[475]\tvalid_0's auc: 0.870506\n",
      "[476]\tvalid_0's auc: 0.870525\n",
      "[477]\tvalid_0's auc: 0.870598\n",
      "[478]\tvalid_0's auc: 0.870661\n",
      "[479]\tvalid_0's auc: 0.870749\n",
      "[480]\tvalid_0's auc: 0.870812\n",
      "[481]\tvalid_0's auc: 0.870887\n",
      "[482]\tvalid_0's auc: 0.87094\n",
      "[483]\tvalid_0's auc: 0.870996\n",
      "[484]\tvalid_0's auc: 0.871056\n",
      "[485]\tvalid_0's auc: 0.871094\n",
      "[486]\tvalid_0's auc: 0.871141\n",
      "[487]\tvalid_0's auc: 0.871199\n",
      "[488]\tvalid_0's auc: 0.871235\n",
      "[489]\tvalid_0's auc: 0.87126\n",
      "[490]\tvalid_0's auc: 0.871348\n",
      "[491]\tvalid_0's auc: 0.87138\n",
      "[492]\tvalid_0's auc: 0.871466\n",
      "[493]\tvalid_0's auc: 0.871532\n",
      "[494]\tvalid_0's auc: 0.871585\n",
      "[495]\tvalid_0's auc: 0.871664\n",
      "[496]\tvalid_0's auc: 0.871733\n",
      "[497]\tvalid_0's auc: 0.871769\n",
      "[498]\tvalid_0's auc: 0.871837\n",
      "[499]\tvalid_0's auc: 0.871924\n",
      "[500]\tvalid_0's auc: 0.872052\n",
      "[501]\tvalid_0's auc: 0.872095\n",
      "[502]\tvalid_0's auc: 0.872153\n",
      "[503]\tvalid_0's auc: 0.87222\n",
      "[504]\tvalid_0's auc: 0.872261\n",
      "[505]\tvalid_0's auc: 0.872288\n",
      "[506]\tvalid_0's auc: 0.872378\n",
      "[507]\tvalid_0's auc: 0.872418\n",
      "[508]\tvalid_0's auc: 0.872489\n",
      "[509]\tvalid_0's auc: 0.872494\n",
      "[510]\tvalid_0's auc: 0.872558\n",
      "[511]\tvalid_0's auc: 0.872588\n",
      "[512]\tvalid_0's auc: 0.872596\n",
      "[513]\tvalid_0's auc: 0.872653\n",
      "[514]\tvalid_0's auc: 0.872747\n",
      "[515]\tvalid_0's auc: 0.872802\n",
      "[516]\tvalid_0's auc: 0.872884\n",
      "[517]\tvalid_0's auc: 0.872919\n",
      "[518]\tvalid_0's auc: 0.873004\n",
      "[519]\tvalid_0's auc: 0.873034\n",
      "[520]\tvalid_0's auc: 0.873065\n",
      "[521]\tvalid_0's auc: 0.87316\n",
      "[522]\tvalid_0's auc: 0.873257\n",
      "[523]\tvalid_0's auc: 0.873307\n",
      "[524]\tvalid_0's auc: 0.873354\n",
      "[525]\tvalid_0's auc: 0.873402\n",
      "[526]\tvalid_0's auc: 0.8734\n",
      "[527]\tvalid_0's auc: 0.873441\n",
      "[528]\tvalid_0's auc: 0.873517\n",
      "[529]\tvalid_0's auc: 0.87361\n",
      "[530]\tvalid_0's auc: 0.873585\n",
      "[531]\tvalid_0's auc: 0.873672\n",
      "[532]\tvalid_0's auc: 0.87376\n",
      "[533]\tvalid_0's auc: 0.873819\n",
      "[534]\tvalid_0's auc: 0.873903\n",
      "[535]\tvalid_0's auc: 0.873898\n",
      "[536]\tvalid_0's auc: 0.873903\n",
      "[537]\tvalid_0's auc: 0.873943\n",
      "[538]\tvalid_0's auc: 0.874053\n",
      "[539]\tvalid_0's auc: 0.874082\n",
      "[540]\tvalid_0's auc: 0.874131\n",
      "[541]\tvalid_0's auc: 0.874203\n",
      "[542]\tvalid_0's auc: 0.874252\n",
      "[543]\tvalid_0's auc: 0.874316\n",
      "[544]\tvalid_0's auc: 0.874402\n",
      "[545]\tvalid_0's auc: 0.874463\n",
      "[546]\tvalid_0's auc: 0.874521\n",
      "[547]\tvalid_0's auc: 0.874556\n",
      "[548]\tvalid_0's auc: 0.874636\n",
      "[549]\tvalid_0's auc: 0.87466\n",
      "[550]\tvalid_0's auc: 0.874726\n",
      "[551]\tvalid_0's auc: 0.874789\n",
      "[552]\tvalid_0's auc: 0.874825\n",
      "[553]\tvalid_0's auc: 0.874884\n",
      "[554]\tvalid_0's auc: 0.874894\n",
      "[555]\tvalid_0's auc: 0.87494\n",
      "[556]\tvalid_0's auc: 0.874993\n",
      "[557]\tvalid_0's auc: 0.875073\n",
      "[558]\tvalid_0's auc: 0.875109\n",
      "[559]\tvalid_0's auc: 0.875144\n",
      "[560]\tvalid_0's auc: 0.875193\n",
      "[561]\tvalid_0's auc: 0.875266\n",
      "[562]\tvalid_0's auc: 0.87534\n",
      "[563]\tvalid_0's auc: 0.875374\n",
      "[564]\tvalid_0's auc: 0.875438\n",
      "[565]\tvalid_0's auc: 0.875497\n",
      "[566]\tvalid_0's auc: 0.875593\n",
      "[567]\tvalid_0's auc: 0.875649\n",
      "[568]\tvalid_0's auc: 0.875658\n",
      "[569]\tvalid_0's auc: 0.875716\n",
      "[570]\tvalid_0's auc: 0.875778\n",
      "[571]\tvalid_0's auc: 0.875827\n",
      "[572]\tvalid_0's auc: 0.875893\n",
      "[573]\tvalid_0's auc: 0.875932\n",
      "[574]\tvalid_0's auc: 0.875968\n",
      "[575]\tvalid_0's auc: 0.876054\n",
      "[576]\tvalid_0's auc: 0.876094\n",
      "[577]\tvalid_0's auc: 0.876114\n",
      "[578]\tvalid_0's auc: 0.876159\n",
      "[579]\tvalid_0's auc: 0.876198\n",
      "[580]\tvalid_0's auc: 0.876276\n",
      "[581]\tvalid_0's auc: 0.876374\n",
      "[582]\tvalid_0's auc: 0.876358\n",
      "[583]\tvalid_0's auc: 0.876377\n",
      "[584]\tvalid_0's auc: 0.876411\n",
      "[585]\tvalid_0's auc: 0.876447\n",
      "[586]\tvalid_0's auc: 0.876482\n",
      "[587]\tvalid_0's auc: 0.876535\n",
      "[588]\tvalid_0's auc: 0.876575\n",
      "[589]\tvalid_0's auc: 0.876625\n",
      "[590]\tvalid_0's auc: 0.87671\n",
      "[591]\tvalid_0's auc: 0.876737\n",
      "[592]\tvalid_0's auc: 0.876791\n",
      "[593]\tvalid_0's auc: 0.87687\n",
      "[594]\tvalid_0's auc: 0.876897\n",
      "[595]\tvalid_0's auc: 0.876917\n",
      "[596]\tvalid_0's auc: 0.876949\n",
      "[597]\tvalid_0's auc: 0.876986\n",
      "[598]\tvalid_0's auc: 0.877005\n",
      "[599]\tvalid_0's auc: 0.877088\n",
      "[600]\tvalid_0's auc: 0.877154\n",
      "[601]\tvalid_0's auc: 0.877226\n",
      "[602]\tvalid_0's auc: 0.87726\n",
      "[603]\tvalid_0's auc: 0.877311\n",
      "[604]\tvalid_0's auc: 0.877315\n",
      "[605]\tvalid_0's auc: 0.877339\n",
      "[606]\tvalid_0's auc: 0.877399\n",
      "[607]\tvalid_0's auc: 0.877448\n",
      "[608]\tvalid_0's auc: 0.877498\n",
      "[609]\tvalid_0's auc: 0.87753\n",
      "[610]\tvalid_0's auc: 0.877572\n",
      "[611]\tvalid_0's auc: 0.877638\n",
      "[612]\tvalid_0's auc: 0.87764\n",
      "[613]\tvalid_0's auc: 0.877694\n",
      "[614]\tvalid_0's auc: 0.877719\n",
      "[615]\tvalid_0's auc: 0.877733\n",
      "[616]\tvalid_0's auc: 0.877763\n",
      "[617]\tvalid_0's auc: 0.8778\n",
      "[618]\tvalid_0's auc: 0.877812\n",
      "[619]\tvalid_0's auc: 0.877831\n",
      "[620]\tvalid_0's auc: 0.877864\n",
      "[621]\tvalid_0's auc: 0.877885\n",
      "[622]\tvalid_0's auc: 0.877923\n",
      "[623]\tvalid_0's auc: 0.877949\n",
      "[624]\tvalid_0's auc: 0.877994\n",
      "[625]\tvalid_0's auc: 0.878027\n",
      "[626]\tvalid_0's auc: 0.878047\n",
      "[627]\tvalid_0's auc: 0.878039\n",
      "[628]\tvalid_0's auc: 0.878067\n",
      "[629]\tvalid_0's auc: 0.87806\n",
      "[630]\tvalid_0's auc: 0.878106\n",
      "[631]\tvalid_0's auc: 0.878168\n",
      "[632]\tvalid_0's auc: 0.878203\n",
      "[633]\tvalid_0's auc: 0.878241\n",
      "[634]\tvalid_0's auc: 0.8783\n",
      "[635]\tvalid_0's auc: 0.878349\n",
      "[636]\tvalid_0's auc: 0.878369\n",
      "[637]\tvalid_0's auc: 0.878417\n",
      "[638]\tvalid_0's auc: 0.878489\n",
      "[639]\tvalid_0's auc: 0.878524\n",
      "[640]\tvalid_0's auc: 0.878548\n",
      "[641]\tvalid_0's auc: 0.878588\n",
      "[642]\tvalid_0's auc: 0.878623\n",
      "[643]\tvalid_0's auc: 0.878651\n",
      "[644]\tvalid_0's auc: 0.87871\n",
      "[645]\tvalid_0's auc: 0.878749\n",
      "[646]\tvalid_0's auc: 0.878812\n",
      "[647]\tvalid_0's auc: 0.878812\n",
      "[648]\tvalid_0's auc: 0.878837\n",
      "[649]\tvalid_0's auc: 0.878886\n",
      "[650]\tvalid_0's auc: 0.878887\n",
      "[651]\tvalid_0's auc: 0.878919\n",
      "[652]\tvalid_0's auc: 0.878925\n",
      "[653]\tvalid_0's auc: 0.878967\n",
      "[654]\tvalid_0's auc: 0.878995\n",
      "[655]\tvalid_0's auc: 0.879051\n",
      "[656]\tvalid_0's auc: 0.879069\n",
      "[657]\tvalid_0's auc: 0.879075\n",
      "[658]\tvalid_0's auc: 0.879128\n",
      "[659]\tvalid_0's auc: 0.879187\n",
      "[660]\tvalid_0's auc: 0.879211\n",
      "[661]\tvalid_0's auc: 0.879238\n",
      "[662]\tvalid_0's auc: 0.879298\n",
      "[663]\tvalid_0's auc: 0.87936\n",
      "[664]\tvalid_0's auc: 0.879391\n",
      "[665]\tvalid_0's auc: 0.879445\n",
      "[666]\tvalid_0's auc: 0.879442\n",
      "[667]\tvalid_0's auc: 0.879467\n",
      "[668]\tvalid_0's auc: 0.879493\n",
      "[669]\tvalid_0's auc: 0.87957\n",
      "[670]\tvalid_0's auc: 0.879615\n",
      "[671]\tvalid_0's auc: 0.879678\n",
      "[672]\tvalid_0's auc: 0.879716\n",
      "[673]\tvalid_0's auc: 0.879711\n",
      "[674]\tvalid_0's auc: 0.879753\n",
      "[675]\tvalid_0's auc: 0.87977\n",
      "[676]\tvalid_0's auc: 0.879803\n",
      "[677]\tvalid_0's auc: 0.87984\n",
      "[678]\tvalid_0's auc: 0.879853\n",
      "[679]\tvalid_0's auc: 0.87987\n",
      "[680]\tvalid_0's auc: 0.879903\n",
      "[681]\tvalid_0's auc: 0.879942\n",
      "[682]\tvalid_0's auc: 0.879921\n",
      "[683]\tvalid_0's auc: 0.879948\n",
      "[684]\tvalid_0's auc: 0.879935\n",
      "[685]\tvalid_0's auc: 0.879943\n",
      "[686]\tvalid_0's auc: 0.879973\n",
      "[687]\tvalid_0's auc: 0.880011\n",
      "[688]\tvalid_0's auc: 0.880021\n",
      "[689]\tvalid_0's auc: 0.88007\n",
      "[690]\tvalid_0's auc: 0.880105\n",
      "[691]\tvalid_0's auc: 0.880092\n",
      "[692]\tvalid_0's auc: 0.880131\n",
      "[693]\tvalid_0's auc: 0.88015\n",
      "[694]\tvalid_0's auc: 0.880169\n",
      "[695]\tvalid_0's auc: 0.880206\n",
      "[696]\tvalid_0's auc: 0.880208\n",
      "[697]\tvalid_0's auc: 0.880239\n",
      "[698]\tvalid_0's auc: 0.880288\n",
      "[699]\tvalid_0's auc: 0.880309\n",
      "[700]\tvalid_0's auc: 0.880358\n",
      "[701]\tvalid_0's auc: 0.880365\n",
      "[702]\tvalid_0's auc: 0.880382\n",
      "[703]\tvalid_0's auc: 0.880407\n",
      "[704]\tvalid_0's auc: 0.880409\n",
      "[705]\tvalid_0's auc: 0.88045\n",
      "[706]\tvalid_0's auc: 0.880446\n",
      "[707]\tvalid_0's auc: 0.880474\n",
      "[708]\tvalid_0's auc: 0.880507\n",
      "[709]\tvalid_0's auc: 0.88054\n",
      "[710]\tvalid_0's auc: 0.880556\n",
      "[711]\tvalid_0's auc: 0.88055\n",
      "[712]\tvalid_0's auc: 0.880562\n",
      "[713]\tvalid_0's auc: 0.880585\n",
      "[714]\tvalid_0's auc: 0.880582\n",
      "[715]\tvalid_0's auc: 0.880601\n",
      "[716]\tvalid_0's auc: 0.880629\n",
      "[717]\tvalid_0's auc: 0.880668\n",
      "[718]\tvalid_0's auc: 0.88069\n",
      "[719]\tvalid_0's auc: 0.880728\n",
      "[720]\tvalid_0's auc: 0.880732\n",
      "[721]\tvalid_0's auc: 0.880747\n",
      "[722]\tvalid_0's auc: 0.880838\n",
      "[723]\tvalid_0's auc: 0.880868\n",
      "[724]\tvalid_0's auc: 0.880927\n",
      "[725]\tvalid_0's auc: 0.880973\n",
      "[726]\tvalid_0's auc: 0.881046\n",
      "[727]\tvalid_0's auc: 0.881104\n",
      "[728]\tvalid_0's auc: 0.881152\n",
      "[729]\tvalid_0's auc: 0.881192\n",
      "[730]\tvalid_0's auc: 0.881207\n",
      "[731]\tvalid_0's auc: 0.881233\n",
      "[732]\tvalid_0's auc: 0.88128\n",
      "[733]\tvalid_0's auc: 0.8813\n",
      "[734]\tvalid_0's auc: 0.881325\n",
      "[735]\tvalid_0's auc: 0.88134\n",
      "[736]\tvalid_0's auc: 0.881383\n",
      "[737]\tvalid_0's auc: 0.881402\n",
      "[738]\tvalid_0's auc: 0.881368\n",
      "[739]\tvalid_0's auc: 0.881401\n",
      "[740]\tvalid_0's auc: 0.881417\n",
      "[741]\tvalid_0's auc: 0.881491\n",
      "[742]\tvalid_0's auc: 0.881529\n",
      "[743]\tvalid_0's auc: 0.881589\n",
      "[744]\tvalid_0's auc: 0.881644\n",
      "[745]\tvalid_0's auc: 0.881701\n",
      "[746]\tvalid_0's auc: 0.881727\n",
      "[747]\tvalid_0's auc: 0.88175\n",
      "[748]\tvalid_0's auc: 0.881771\n",
      "[749]\tvalid_0's auc: 0.881802\n",
      "[750]\tvalid_0's auc: 0.881857\n",
      "[751]\tvalid_0's auc: 0.881879\n",
      "[752]\tvalid_0's auc: 0.881915\n",
      "[753]\tvalid_0's auc: 0.881947\n",
      "[754]\tvalid_0's auc: 0.881975\n",
      "[755]\tvalid_0's auc: 0.882001\n",
      "[756]\tvalid_0's auc: 0.882032\n",
      "[757]\tvalid_0's auc: 0.882097\n",
      "[758]\tvalid_0's auc: 0.882108\n",
      "[759]\tvalid_0's auc: 0.882176\n",
      "[760]\tvalid_0's auc: 0.882184\n",
      "[761]\tvalid_0's auc: 0.882234\n",
      "[762]\tvalid_0's auc: 0.882282\n",
      "[763]\tvalid_0's auc: 0.882294\n",
      "[764]\tvalid_0's auc: 0.88232\n",
      "[765]\tvalid_0's auc: 0.882337\n",
      "[766]\tvalid_0's auc: 0.882386\n",
      "[767]\tvalid_0's auc: 0.88242\n",
      "[768]\tvalid_0's auc: 0.882446\n",
      "[769]\tvalid_0's auc: 0.882494\n",
      "[770]\tvalid_0's auc: 0.882528\n",
      "[771]\tvalid_0's auc: 0.882556\n",
      "[772]\tvalid_0's auc: 0.882629\n",
      "[773]\tvalid_0's auc: 0.882674\n",
      "[774]\tvalid_0's auc: 0.882695\n",
      "[775]\tvalid_0's auc: 0.882728\n",
      "[776]\tvalid_0's auc: 0.882764\n",
      "[777]\tvalid_0's auc: 0.882806\n",
      "[778]\tvalid_0's auc: 0.88285\n",
      "[779]\tvalid_0's auc: 0.882872\n",
      "[780]\tvalid_0's auc: 0.88291\n",
      "[781]\tvalid_0's auc: 0.882911\n",
      "[782]\tvalid_0's auc: 0.882958\n",
      "[783]\tvalid_0's auc: 0.882967\n",
      "[784]\tvalid_0's auc: 0.883004\n",
      "[785]\tvalid_0's auc: 0.883038\n",
      "[786]\tvalid_0's auc: 0.88304\n",
      "[787]\tvalid_0's auc: 0.883063\n",
      "[788]\tvalid_0's auc: 0.883092\n",
      "[789]\tvalid_0's auc: 0.883123\n",
      "[790]\tvalid_0's auc: 0.883141\n",
      "[791]\tvalid_0's auc: 0.883166\n",
      "[792]\tvalid_0's auc: 0.883144\n",
      "[793]\tvalid_0's auc: 0.883171\n",
      "[794]\tvalid_0's auc: 0.883167\n",
      "[795]\tvalid_0's auc: 0.883171\n",
      "[796]\tvalid_0's auc: 0.883201\n",
      "[797]\tvalid_0's auc: 0.883224\n",
      "[798]\tvalid_0's auc: 0.88326\n",
      "[799]\tvalid_0's auc: 0.883297\n",
      "[800]\tvalid_0's auc: 0.883322\n",
      "[801]\tvalid_0's auc: 0.883331\n",
      "[802]\tvalid_0's auc: 0.883347\n",
      "[803]\tvalid_0's auc: 0.883379\n",
      "[804]\tvalid_0's auc: 0.883398\n",
      "[805]\tvalid_0's auc: 0.883437\n",
      "[806]\tvalid_0's auc: 0.883477\n",
      "[807]\tvalid_0's auc: 0.883504\n",
      "[808]\tvalid_0's auc: 0.883537\n",
      "[809]\tvalid_0's auc: 0.88356\n",
      "[810]\tvalid_0's auc: 0.883597\n",
      "[811]\tvalid_0's auc: 0.88364\n",
      "[812]\tvalid_0's auc: 0.883653\n",
      "[813]\tvalid_0's auc: 0.883676\n",
      "[814]\tvalid_0's auc: 0.883692\n",
      "[815]\tvalid_0's auc: 0.883709\n",
      "[816]\tvalid_0's auc: 0.883756\n",
      "[817]\tvalid_0's auc: 0.883783\n",
      "[818]\tvalid_0's auc: 0.883811\n",
      "[819]\tvalid_0's auc: 0.883845\n",
      "[820]\tvalid_0's auc: 0.883848\n",
      "[821]\tvalid_0's auc: 0.883862\n",
      "[822]\tvalid_0's auc: 0.883893\n",
      "[823]\tvalid_0's auc: 0.883929\n",
      "[824]\tvalid_0's auc: 0.883916\n",
      "[825]\tvalid_0's auc: 0.883937\n",
      "[826]\tvalid_0's auc: 0.883936\n",
      "[827]\tvalid_0's auc: 0.883943\n",
      "[828]\tvalid_0's auc: 0.883955\n",
      "[829]\tvalid_0's auc: 0.88398\n",
      "[830]\tvalid_0's auc: 0.883995\n",
      "[831]\tvalid_0's auc: 0.884022\n",
      "[832]\tvalid_0's auc: 0.884065\n",
      "[833]\tvalid_0's auc: 0.884062\n",
      "[834]\tvalid_0's auc: 0.884065\n",
      "[835]\tvalid_0's auc: 0.884074\n",
      "[836]\tvalid_0's auc: 0.884091\n",
      "[837]\tvalid_0's auc: 0.884064\n",
      "[838]\tvalid_0's auc: 0.884078\n",
      "[839]\tvalid_0's auc: 0.884069\n",
      "[840]\tvalid_0's auc: 0.884081\n",
      "[841]\tvalid_0's auc: 0.884091\n",
      "[842]\tvalid_0's auc: 0.88412\n",
      "[843]\tvalid_0's auc: 0.88416\n",
      "[844]\tvalid_0's auc: 0.884169\n",
      "[845]\tvalid_0's auc: 0.884211\n",
      "[846]\tvalid_0's auc: 0.884227\n",
      "[847]\tvalid_0's auc: 0.884283\n",
      "[848]\tvalid_0's auc: 0.884311\n",
      "[849]\tvalid_0's auc: 0.884329\n",
      "[850]\tvalid_0's auc: 0.884348\n",
      "[851]\tvalid_0's auc: 0.884396\n",
      "[852]\tvalid_0's auc: 0.884415\n",
      "[853]\tvalid_0's auc: 0.884446\n",
      "[854]\tvalid_0's auc: 0.884479\n",
      "[855]\tvalid_0's auc: 0.8845\n",
      "[856]\tvalid_0's auc: 0.884526\n",
      "[857]\tvalid_0's auc: 0.884566\n",
      "[858]\tvalid_0's auc: 0.884598\n",
      "[859]\tvalid_0's auc: 0.884645\n",
      "[860]\tvalid_0's auc: 0.884632\n",
      "[861]\tvalid_0's auc: 0.884635\n",
      "[862]\tvalid_0's auc: 0.884629\n",
      "[863]\tvalid_0's auc: 0.884652\n",
      "[864]\tvalid_0's auc: 0.884663\n",
      "[865]\tvalid_0's auc: 0.884691\n",
      "[866]\tvalid_0's auc: 0.88475\n",
      "[867]\tvalid_0's auc: 0.884808\n",
      "[868]\tvalid_0's auc: 0.884825\n",
      "[869]\tvalid_0's auc: 0.884836\n",
      "[870]\tvalid_0's auc: 0.884843\n",
      "[871]\tvalid_0's auc: 0.884847\n",
      "[872]\tvalid_0's auc: 0.884842\n",
      "[873]\tvalid_0's auc: 0.884872\n",
      "[874]\tvalid_0's auc: 0.88489\n",
      "[875]\tvalid_0's auc: 0.884937\n",
      "[876]\tvalid_0's auc: 0.884968\n",
      "[877]\tvalid_0's auc: 0.885006\n",
      "[878]\tvalid_0's auc: 0.884999\n",
      "[879]\tvalid_0's auc: 0.884985\n",
      "[880]\tvalid_0's auc: 0.885017\n",
      "[881]\tvalid_0's auc: 0.885027\n",
      "[882]\tvalid_0's auc: 0.885062\n",
      "[883]\tvalid_0's auc: 0.885074\n",
      "[884]\tvalid_0's auc: 0.885103\n",
      "[885]\tvalid_0's auc: 0.88512\n",
      "[886]\tvalid_0's auc: 0.885143\n",
      "[887]\tvalid_0's auc: 0.885181\n",
      "[888]\tvalid_0's auc: 0.885229\n",
      "[889]\tvalid_0's auc: 0.885278\n",
      "[890]\tvalid_0's auc: 0.885327\n",
      "[891]\tvalid_0's auc: 0.885355\n",
      "[892]\tvalid_0's auc: 0.885377\n",
      "[893]\tvalid_0's auc: 0.885427\n",
      "[894]\tvalid_0's auc: 0.885434\n",
      "[895]\tvalid_0's auc: 0.885463\n",
      "[896]\tvalid_0's auc: 0.88547\n",
      "[897]\tvalid_0's auc: 0.885487\n",
      "[898]\tvalid_0's auc: 0.885504\n",
      "[899]\tvalid_0's auc: 0.885543\n",
      "[900]\tvalid_0's auc: 0.885541\n",
      "[901]\tvalid_0's auc: 0.885563\n",
      "[902]\tvalid_0's auc: 0.885565\n",
      "[903]\tvalid_0's auc: 0.885574\n",
      "[904]\tvalid_0's auc: 0.885595\n",
      "[905]\tvalid_0's auc: 0.885607\n",
      "[906]\tvalid_0's auc: 0.885657\n",
      "[907]\tvalid_0's auc: 0.885685\n",
      "[908]\tvalid_0's auc: 0.885721\n",
      "[909]\tvalid_0's auc: 0.885717\n",
      "[910]\tvalid_0's auc: 0.885743\n",
      "[911]\tvalid_0's auc: 0.885754\n",
      "[912]\tvalid_0's auc: 0.885772\n",
      "[913]\tvalid_0's auc: 0.885775\n",
      "[914]\tvalid_0's auc: 0.885809\n",
      "[915]\tvalid_0's auc: 0.885825\n",
      "[916]\tvalid_0's auc: 0.885836\n",
      "[917]\tvalid_0's auc: 0.885865\n",
      "[918]\tvalid_0's auc: 0.885874\n",
      "[919]\tvalid_0's auc: 0.885918\n",
      "[920]\tvalid_0's auc: 0.885972\n",
      "[921]\tvalid_0's auc: 0.885986\n",
      "[922]\tvalid_0's auc: 0.886012\n",
      "[923]\tvalid_0's auc: 0.886036\n",
      "[924]\tvalid_0's auc: 0.886055\n",
      "[925]\tvalid_0's auc: 0.886109\n",
      "[926]\tvalid_0's auc: 0.886115\n",
      "[927]\tvalid_0's auc: 0.886138\n",
      "[928]\tvalid_0's auc: 0.886194\n",
      "[929]\tvalid_0's auc: 0.886209\n",
      "[930]\tvalid_0's auc: 0.886257\n",
      "[931]\tvalid_0's auc: 0.886277\n",
      "[932]\tvalid_0's auc: 0.886296\n",
      "[933]\tvalid_0's auc: 0.886318\n",
      "[934]\tvalid_0's auc: 0.88634\n",
      "[935]\tvalid_0's auc: 0.88637\n",
      "[936]\tvalid_0's auc: 0.886431\n",
      "[937]\tvalid_0's auc: 0.886451\n",
      "[938]\tvalid_0's auc: 0.8865\n",
      "[939]\tvalid_0's auc: 0.886515\n",
      "[940]\tvalid_0's auc: 0.886538\n",
      "[941]\tvalid_0's auc: 0.886551\n",
      "[942]\tvalid_0's auc: 0.886591\n",
      "[943]\tvalid_0's auc: 0.886598\n",
      "[944]\tvalid_0's auc: 0.886658\n",
      "[945]\tvalid_0's auc: 0.886676\n",
      "[946]\tvalid_0's auc: 0.886721\n",
      "[947]\tvalid_0's auc: 0.886748\n",
      "[948]\tvalid_0's auc: 0.886784\n",
      "[949]\tvalid_0's auc: 0.88678\n",
      "[950]\tvalid_0's auc: 0.886801\n",
      "[951]\tvalid_0's auc: 0.88681\n",
      "[952]\tvalid_0's auc: 0.886792\n",
      "[953]\tvalid_0's auc: 0.88681\n",
      "[954]\tvalid_0's auc: 0.886834\n",
      "[955]\tvalid_0's auc: 0.886844\n",
      "[956]\tvalid_0's auc: 0.886869\n",
      "[957]\tvalid_0's auc: 0.886884\n",
      "[958]\tvalid_0's auc: 0.886902\n",
      "[959]\tvalid_0's auc: 0.886923\n",
      "[960]\tvalid_0's auc: 0.886941\n",
      "[961]\tvalid_0's auc: 0.886969\n",
      "[962]\tvalid_0's auc: 0.886987\n",
      "[963]\tvalid_0's auc: 0.88701\n",
      "[964]\tvalid_0's auc: 0.887028\n",
      "[965]\tvalid_0's auc: 0.887045\n",
      "[966]\tvalid_0's auc: 0.887068\n",
      "[967]\tvalid_0's auc: 0.887096\n",
      "[968]\tvalid_0's auc: 0.887113\n",
      "[969]\tvalid_0's auc: 0.887121\n",
      "[970]\tvalid_0's auc: 0.887126\n",
      "[971]\tvalid_0's auc: 0.887144\n",
      "[972]\tvalid_0's auc: 0.887157\n",
      "[973]\tvalid_0's auc: 0.887174\n",
      "[974]\tvalid_0's auc: 0.887187\n",
      "[975]\tvalid_0's auc: 0.887199\n",
      "[976]\tvalid_0's auc: 0.887214\n",
      "[977]\tvalid_0's auc: 0.887226\n",
      "[978]\tvalid_0's auc: 0.887281\n",
      "[979]\tvalid_0's auc: 0.887308\n",
      "[980]\tvalid_0's auc: 0.887335\n",
      "[981]\tvalid_0's auc: 0.887344\n",
      "[982]\tvalid_0's auc: 0.88735\n",
      "[983]\tvalid_0's auc: 0.887389\n",
      "[984]\tvalid_0's auc: 0.887393\n",
      "[985]\tvalid_0's auc: 0.887455\n",
      "[986]\tvalid_0's auc: 0.887467\n",
      "[987]\tvalid_0's auc: 0.887497\n",
      "[988]\tvalid_0's auc: 0.88753\n",
      "[989]\tvalid_0's auc: 0.88753\n",
      "[990]\tvalid_0's auc: 0.887547\n",
      "[991]\tvalid_0's auc: 0.887556\n",
      "[992]\tvalid_0's auc: 0.887607\n",
      "[993]\tvalid_0's auc: 0.887622\n",
      "[994]\tvalid_0's auc: 0.887618\n",
      "[995]\tvalid_0's auc: 0.887648\n",
      "[996]\tvalid_0's auc: 0.887671\n",
      "[997]\tvalid_0's auc: 0.887685\n",
      "[998]\tvalid_0's auc: 0.887687\n",
      "[999]\tvalid_0's auc: 0.887682\n",
      "[1000]\tvalid_0's auc: 0.887676\n",
      "[1001]\tvalid_0's auc: 0.887685\n",
      "[1002]\tvalid_0's auc: 0.887698\n",
      "[1003]\tvalid_0's auc: 0.88774\n",
      "[1004]\tvalid_0's auc: 0.88775\n",
      "[1005]\tvalid_0's auc: 0.88777\n",
      "[1006]\tvalid_0's auc: 0.887776\n",
      "[1007]\tvalid_0's auc: 0.887792\n",
      "[1008]\tvalid_0's auc: 0.887783\n",
      "[1009]\tvalid_0's auc: 0.887811\n",
      "[1010]\tvalid_0's auc: 0.887831\n",
      "[1011]\tvalid_0's auc: 0.887862\n",
      "[1012]\tvalid_0's auc: 0.887874\n",
      "[1013]\tvalid_0's auc: 0.887908\n",
      "[1014]\tvalid_0's auc: 0.887917\n",
      "[1015]\tvalid_0's auc: 0.887908\n",
      "[1016]\tvalid_0's auc: 0.887918\n",
      "[1017]\tvalid_0's auc: 0.887935\n",
      "[1018]\tvalid_0's auc: 0.887959\n",
      "[1019]\tvalid_0's auc: 0.887994\n",
      "[1020]\tvalid_0's auc: 0.888013\n",
      "[1021]\tvalid_0's auc: 0.887986\n",
      "[1022]\tvalid_0's auc: 0.887995\n",
      "[1023]\tvalid_0's auc: 0.887993\n",
      "[1024]\tvalid_0's auc: 0.888025\n",
      "[1025]\tvalid_0's auc: 0.88805\n",
      "[1026]\tvalid_0's auc: 0.888087\n",
      "[1027]\tvalid_0's auc: 0.888102\n",
      "[1028]\tvalid_0's auc: 0.888123\n",
      "[1029]\tvalid_0's auc: 0.888138\n",
      "[1030]\tvalid_0's auc: 0.888142\n",
      "[1031]\tvalid_0's auc: 0.888132\n",
      "[1032]\tvalid_0's auc: 0.888135\n",
      "[1033]\tvalid_0's auc: 0.888156\n",
      "[1034]\tvalid_0's auc: 0.88817\n",
      "[1035]\tvalid_0's auc: 0.8882\n",
      "[1036]\tvalid_0's auc: 0.888211\n",
      "[1037]\tvalid_0's auc: 0.888217\n",
      "[1038]\tvalid_0's auc: 0.888204\n",
      "[1039]\tvalid_0's auc: 0.88822\n",
      "[1040]\tvalid_0's auc: 0.888228\n",
      "[1041]\tvalid_0's auc: 0.88825\n",
      "[1042]\tvalid_0's auc: 0.888257\n",
      "[1043]\tvalid_0's auc: 0.888293\n",
      "[1044]\tvalid_0's auc: 0.888294\n",
      "[1045]\tvalid_0's auc: 0.888347\n",
      "[1046]\tvalid_0's auc: 0.88836\n",
      "[1047]\tvalid_0's auc: 0.888379\n",
      "[1048]\tvalid_0's auc: 0.888427\n",
      "[1049]\tvalid_0's auc: 0.88843\n",
      "[1050]\tvalid_0's auc: 0.888459\n",
      "[1051]\tvalid_0's auc: 0.888481\n",
      "[1052]\tvalid_0's auc: 0.888523\n",
      "[1053]\tvalid_0's auc: 0.888549\n",
      "[1054]\tvalid_0's auc: 0.888566\n",
      "[1055]\tvalid_0's auc: 0.888598\n",
      "[1056]\tvalid_0's auc: 0.888619\n",
      "[1057]\tvalid_0's auc: 0.888649\n",
      "[1058]\tvalid_0's auc: 0.888655\n",
      "[1059]\tvalid_0's auc: 0.888684\n",
      "[1060]\tvalid_0's auc: 0.888692\n",
      "[1061]\tvalid_0's auc: 0.88872\n",
      "[1062]\tvalid_0's auc: 0.888729\n",
      "[1063]\tvalid_0's auc: 0.888747\n",
      "[1064]\tvalid_0's auc: 0.888763\n",
      "[1065]\tvalid_0's auc: 0.888792\n",
      "[1066]\tvalid_0's auc: 0.88883\n",
      "[1067]\tvalid_0's auc: 0.888877\n",
      "[1068]\tvalid_0's auc: 0.888914\n",
      "[1069]\tvalid_0's auc: 0.888915\n",
      "[1070]\tvalid_0's auc: 0.888958\n",
      "[1071]\tvalid_0's auc: 0.888989\n",
      "[1072]\tvalid_0's auc: 0.888969\n",
      "[1073]\tvalid_0's auc: 0.888989\n",
      "[1074]\tvalid_0's auc: 0.888989\n",
      "[1075]\tvalid_0's auc: 0.889005\n",
      "[1076]\tvalid_0's auc: 0.889018\n",
      "[1077]\tvalid_0's auc: 0.889039\n",
      "[1078]\tvalid_0's auc: 0.889072\n",
      "[1079]\tvalid_0's auc: 0.889071\n",
      "[1080]\tvalid_0's auc: 0.88907\n",
      "[1081]\tvalid_0's auc: 0.8891\n",
      "[1082]\tvalid_0's auc: 0.889117\n",
      "[1083]\tvalid_0's auc: 0.889136\n",
      "[1084]\tvalid_0's auc: 0.889153\n",
      "[1085]\tvalid_0's auc: 0.889173\n",
      "[1086]\tvalid_0's auc: 0.889162\n",
      "[1087]\tvalid_0's auc: 0.889187\n",
      "[1088]\tvalid_0's auc: 0.889192\n",
      "[1089]\tvalid_0's auc: 0.889199\n",
      "[1090]\tvalid_0's auc: 0.8892\n",
      "[1091]\tvalid_0's auc: 0.889231\n",
      "[1092]\tvalid_0's auc: 0.889256\n",
      "[1093]\tvalid_0's auc: 0.889264\n",
      "[1094]\tvalid_0's auc: 0.889267\n",
      "[1095]\tvalid_0's auc: 0.889285\n",
      "[1096]\tvalid_0's auc: 0.889272\n",
      "[1097]\tvalid_0's auc: 0.889292\n",
      "[1098]\tvalid_0's auc: 0.889307\n",
      "[1099]\tvalid_0's auc: 0.889323\n",
      "[1100]\tvalid_0's auc: 0.889324\n",
      "[1101]\tvalid_0's auc: 0.889329\n",
      "[1102]\tvalid_0's auc: 0.88934\n",
      "[1103]\tvalid_0's auc: 0.889362\n",
      "[1104]\tvalid_0's auc: 0.889351\n",
      "[1105]\tvalid_0's auc: 0.889377\n",
      "[1106]\tvalid_0's auc: 0.88939\n",
      "[1107]\tvalid_0's auc: 0.889387\n",
      "[1108]\tvalid_0's auc: 0.889418\n",
      "[1109]\tvalid_0's auc: 0.889432\n",
      "[1110]\tvalid_0's auc: 0.88946\n",
      "[1111]\tvalid_0's auc: 0.889475\n",
      "[1112]\tvalid_0's auc: 0.889481\n",
      "[1113]\tvalid_0's auc: 0.88948\n",
      "[1114]\tvalid_0's auc: 0.889466\n",
      "[1115]\tvalid_0's auc: 0.88947\n",
      "[1116]\tvalid_0's auc: 0.889472\n",
      "[1117]\tvalid_0's auc: 0.889471\n",
      "[1118]\tvalid_0's auc: 0.889494\n",
      "[1119]\tvalid_0's auc: 0.889502\n",
      "[1120]\tvalid_0's auc: 0.889511\n",
      "[1121]\tvalid_0's auc: 0.889534\n",
      "[1122]\tvalid_0's auc: 0.889563\n",
      "[1123]\tvalid_0's auc: 0.889604\n",
      "[1124]\tvalid_0's auc: 0.889607\n",
      "[1125]\tvalid_0's auc: 0.889613\n",
      "[1126]\tvalid_0's auc: 0.889639\n",
      "[1127]\tvalid_0's auc: 0.889652\n",
      "[1128]\tvalid_0's auc: 0.889664\n",
      "[1129]\tvalid_0's auc: 0.889682\n",
      "[1130]\tvalid_0's auc: 0.889702\n",
      "[1131]\tvalid_0's auc: 0.889726\n",
      "[1132]\tvalid_0's auc: 0.889727\n",
      "[1133]\tvalid_0's auc: 0.889695\n",
      "[1134]\tvalid_0's auc: 0.8897\n",
      "[1135]\tvalid_0's auc: 0.889721\n",
      "[1136]\tvalid_0's auc: 0.889729\n",
      "[1137]\tvalid_0's auc: 0.889751\n",
      "[1138]\tvalid_0's auc: 0.889768\n",
      "[1139]\tvalid_0's auc: 0.889764\n",
      "[1140]\tvalid_0's auc: 0.889805\n",
      "[1141]\tvalid_0's auc: 0.88981\n",
      "[1142]\tvalid_0's auc: 0.88982\n",
      "[1143]\tvalid_0's auc: 0.889831\n",
      "[1144]\tvalid_0's auc: 0.88984\n",
      "[1145]\tvalid_0's auc: 0.889853\n",
      "[1146]\tvalid_0's auc: 0.889864\n",
      "[1147]\tvalid_0's auc: 0.88988\n",
      "[1148]\tvalid_0's auc: 0.889895\n",
      "[1149]\tvalid_0's auc: 0.889909\n",
      "[1150]\tvalid_0's auc: 0.889876\n",
      "[1151]\tvalid_0's auc: 0.889885\n",
      "[1152]\tvalid_0's auc: 0.889882\n",
      "[1153]\tvalid_0's auc: 0.889898\n",
      "[1154]\tvalid_0's auc: 0.889893\n",
      "[1155]\tvalid_0's auc: 0.889909\n",
      "[1156]\tvalid_0's auc: 0.889912\n",
      "[1157]\tvalid_0's auc: 0.889936\n",
      "[1158]\tvalid_0's auc: 0.889975\n",
      "[1159]\tvalid_0's auc: 0.889973\n",
      "[1160]\tvalid_0's auc: 0.889981\n",
      "[1161]\tvalid_0's auc: 0.889997\n",
      "[1162]\tvalid_0's auc: 0.890014\n",
      "[1163]\tvalid_0's auc: 0.890037\n",
      "[1164]\tvalid_0's auc: 0.890067\n",
      "[1165]\tvalid_0's auc: 0.890059\n",
      "[1166]\tvalid_0's auc: 0.890064\n",
      "[1167]\tvalid_0's auc: 0.890077\n",
      "[1168]\tvalid_0's auc: 0.890064\n",
      "[1169]\tvalid_0's auc: 0.890078\n",
      "[1170]\tvalid_0's auc: 0.890087\n",
      "[1171]\tvalid_0's auc: 0.89008\n",
      "[1172]\tvalid_0's auc: 0.890116\n",
      "[1173]\tvalid_0's auc: 0.890134\n",
      "[1174]\tvalid_0's auc: 0.890128\n",
      "[1175]\tvalid_0's auc: 0.890158\n",
      "[1176]\tvalid_0's auc: 0.890179\n",
      "[1177]\tvalid_0's auc: 0.890208\n",
      "[1178]\tvalid_0's auc: 0.89021\n",
      "[1179]\tvalid_0's auc: 0.890224\n",
      "[1180]\tvalid_0's auc: 0.890235\n",
      "[1181]\tvalid_0's auc: 0.890282\n",
      "[1182]\tvalid_0's auc: 0.89032\n",
      "[1183]\tvalid_0's auc: 0.890332\n",
      "[1184]\tvalid_0's auc: 0.890331\n",
      "[1185]\tvalid_0's auc: 0.890363\n",
      "[1186]\tvalid_0's auc: 0.890376\n",
      "[1187]\tvalid_0's auc: 0.890395\n",
      "[1188]\tvalid_0's auc: 0.890418\n",
      "[1189]\tvalid_0's auc: 0.890459\n",
      "[1190]\tvalid_0's auc: 0.89049\n",
      "[1191]\tvalid_0's auc: 0.890502\n",
      "[1192]\tvalid_0's auc: 0.890544\n",
      "[1193]\tvalid_0's auc: 0.89056\n",
      "[1194]\tvalid_0's auc: 0.890587\n",
      "[1195]\tvalid_0's auc: 0.890586\n",
      "[1196]\tvalid_0's auc: 0.890623\n",
      "[1197]\tvalid_0's auc: 0.890643\n",
      "[1198]\tvalid_0's auc: 0.890683\n",
      "[1199]\tvalid_0's auc: 0.890696\n",
      "[1200]\tvalid_0's auc: 0.890718\n",
      "[1201]\tvalid_0's auc: 0.890724\n",
      "[1202]\tvalid_0's auc: 0.890735\n",
      "[1203]\tvalid_0's auc: 0.89074\n",
      "[1204]\tvalid_0's auc: 0.89075\n",
      "[1205]\tvalid_0's auc: 0.89075\n",
      "[1206]\tvalid_0's auc: 0.890746\n",
      "[1207]\tvalid_0's auc: 0.890761\n",
      "[1208]\tvalid_0's auc: 0.890768\n",
      "[1209]\tvalid_0's auc: 0.890786\n",
      "[1210]\tvalid_0's auc: 0.890788\n",
      "[1211]\tvalid_0's auc: 0.890817\n",
      "[1212]\tvalid_0's auc: 0.890819\n",
      "[1213]\tvalid_0's auc: 0.890833\n",
      "[1214]\tvalid_0's auc: 0.890832\n",
      "[1215]\tvalid_0's auc: 0.890858\n",
      "[1216]\tvalid_0's auc: 0.890868\n",
      "[1217]\tvalid_0's auc: 0.890884\n",
      "[1218]\tvalid_0's auc: 0.890895\n",
      "[1219]\tvalid_0's auc: 0.890914\n",
      "[1220]\tvalid_0's auc: 0.890921\n",
      "[1221]\tvalid_0's auc: 0.890942\n",
      "[1222]\tvalid_0's auc: 0.890982\n",
      "[1223]\tvalid_0's auc: 0.891017\n",
      "[1224]\tvalid_0's auc: 0.891016\n",
      "[1225]\tvalid_0's auc: 0.891026\n",
      "[1226]\tvalid_0's auc: 0.891048\n",
      "[1227]\tvalid_0's auc: 0.891061\n",
      "[1228]\tvalid_0's auc: 0.891103\n",
      "[1229]\tvalid_0's auc: 0.891114\n",
      "[1230]\tvalid_0's auc: 0.891148\n",
      "[1231]\tvalid_0's auc: 0.891152\n",
      "[1232]\tvalid_0's auc: 0.891152\n",
      "[1233]\tvalid_0's auc: 0.891187\n",
      "[1234]\tvalid_0's auc: 0.891214\n",
      "[1235]\tvalid_0's auc: 0.891234\n",
      "[1236]\tvalid_0's auc: 0.891274\n",
      "[1237]\tvalid_0's auc: 0.891286\n",
      "[1238]\tvalid_0's auc: 0.891288\n",
      "[1239]\tvalid_0's auc: 0.891294\n",
      "[1240]\tvalid_0's auc: 0.891305\n",
      "[1241]\tvalid_0's auc: 0.891328\n",
      "[1242]\tvalid_0's auc: 0.89134\n",
      "[1243]\tvalid_0's auc: 0.891339\n",
      "[1244]\tvalid_0's auc: 0.891365\n",
      "[1245]\tvalid_0's auc: 0.891393\n",
      "[1246]\tvalid_0's auc: 0.891397\n",
      "[1247]\tvalid_0's auc: 0.891416\n",
      "[1248]\tvalid_0's auc: 0.891418\n",
      "[1249]\tvalid_0's auc: 0.891439\n",
      "[1250]\tvalid_0's auc: 0.891452\n",
      "[1251]\tvalid_0's auc: 0.891474\n",
      "[1252]\tvalid_0's auc: 0.891471\n",
      "[1253]\tvalid_0's auc: 0.89147\n",
      "[1254]\tvalid_0's auc: 0.891474\n",
      "[1255]\tvalid_0's auc: 0.891493\n",
      "[1256]\tvalid_0's auc: 0.891498\n",
      "[1257]\tvalid_0's auc: 0.8915\n",
      "[1258]\tvalid_0's auc: 0.891514\n",
      "[1259]\tvalid_0's auc: 0.891529\n",
      "[1260]\tvalid_0's auc: 0.891545\n",
      "[1261]\tvalid_0's auc: 0.891568\n",
      "[1262]\tvalid_0's auc: 0.891571\n",
      "[1263]\tvalid_0's auc: 0.891604\n",
      "[1264]\tvalid_0's auc: 0.891615\n",
      "[1265]\tvalid_0's auc: 0.891606\n",
      "[1266]\tvalid_0's auc: 0.891634\n",
      "[1267]\tvalid_0's auc: 0.891654\n",
      "[1268]\tvalid_0's auc: 0.891678\n",
      "[1269]\tvalid_0's auc: 0.891694\n",
      "[1270]\tvalid_0's auc: 0.891709\n",
      "[1271]\tvalid_0's auc: 0.891739\n",
      "[1272]\tvalid_0's auc: 0.89175\n",
      "[1273]\tvalid_0's auc: 0.891767\n",
      "[1274]\tvalid_0's auc: 0.89176\n",
      "[1275]\tvalid_0's auc: 0.891763\n",
      "[1276]\tvalid_0's auc: 0.891762\n",
      "[1277]\tvalid_0's auc: 0.891804\n",
      "[1278]\tvalid_0's auc: 0.891831\n",
      "[1279]\tvalid_0's auc: 0.891835\n",
      "[1280]\tvalid_0's auc: 0.891842\n",
      "[1281]\tvalid_0's auc: 0.891861\n",
      "[1282]\tvalid_0's auc: 0.891886\n",
      "[1283]\tvalid_0's auc: 0.891873\n",
      "[1284]\tvalid_0's auc: 0.891889\n",
      "[1285]\tvalid_0's auc: 0.891891\n",
      "[1286]\tvalid_0's auc: 0.891889\n",
      "[1287]\tvalid_0's auc: 0.891912\n",
      "[1288]\tvalid_0's auc: 0.891926\n",
      "[1289]\tvalid_0's auc: 0.89193\n",
      "[1290]\tvalid_0's auc: 0.89193\n",
      "[1291]\tvalid_0's auc: 0.891938\n",
      "[1292]\tvalid_0's auc: 0.891945\n",
      "[1293]\tvalid_0's auc: 0.891962\n",
      "[1294]\tvalid_0's auc: 0.891967\n",
      "[1295]\tvalid_0's auc: 0.891961\n",
      "[1296]\tvalid_0's auc: 0.891971\n",
      "[1297]\tvalid_0's auc: 0.891993\n",
      "[1298]\tvalid_0's auc: 0.891986\n",
      "[1299]\tvalid_0's auc: 0.892008\n",
      "[1300]\tvalid_0's auc: 0.892002\n",
      "[1301]\tvalid_0's auc: 0.892025\n",
      "[1302]\tvalid_0's auc: 0.892058\n",
      "[1303]\tvalid_0's auc: 0.89209\n",
      "[1304]\tvalid_0's auc: 0.892089\n",
      "[1305]\tvalid_0's auc: 0.892103\n",
      "[1306]\tvalid_0's auc: 0.892129\n",
      "[1307]\tvalid_0's auc: 0.89215\n",
      "[1308]\tvalid_0's auc: 0.892169\n",
      "[1309]\tvalid_0's auc: 0.892186\n",
      "[1310]\tvalid_0's auc: 0.892198\n",
      "[1311]\tvalid_0's auc: 0.892221\n",
      "[1312]\tvalid_0's auc: 0.892219\n",
      "[1313]\tvalid_0's auc: 0.892245\n",
      "[1314]\tvalid_0's auc: 0.892245\n",
      "[1315]\tvalid_0's auc: 0.892247\n",
      "[1316]\tvalid_0's auc: 0.892269\n",
      "[1317]\tvalid_0's auc: 0.892283\n",
      "[1318]\tvalid_0's auc: 0.892302\n",
      "[1319]\tvalid_0's auc: 0.892295\n",
      "[1320]\tvalid_0's auc: 0.892299\n",
      "[1321]\tvalid_0's auc: 0.8923\n",
      "[1322]\tvalid_0's auc: 0.892319\n",
      "[1323]\tvalid_0's auc: 0.892332\n",
      "[1324]\tvalid_0's auc: 0.892354\n",
      "[1325]\tvalid_0's auc: 0.892356\n",
      "[1326]\tvalid_0's auc: 0.892382\n",
      "[1327]\tvalid_0's auc: 0.892395\n",
      "[1328]\tvalid_0's auc: 0.892409\n",
      "[1329]\tvalid_0's auc: 0.892437\n",
      "[1330]\tvalid_0's auc: 0.892435\n",
      "[1331]\tvalid_0's auc: 0.892457\n",
      "[1332]\tvalid_0's auc: 0.892449\n",
      "[1333]\tvalid_0's auc: 0.892439\n",
      "[1334]\tvalid_0's auc: 0.892442\n",
      "[1335]\tvalid_0's auc: 0.892438\n",
      "[1336]\tvalid_0's auc: 0.892456\n",
      "[1337]\tvalid_0's auc: 0.892447\n",
      "[1338]\tvalid_0's auc: 0.892467\n",
      "[1339]\tvalid_0's auc: 0.892466\n",
      "[1340]\tvalid_0's auc: 0.892475\n",
      "[1341]\tvalid_0's auc: 0.892491\n",
      "[1342]\tvalid_0's auc: 0.892491\n",
      "[1343]\tvalid_0's auc: 0.892506\n",
      "[1344]\tvalid_0's auc: 0.892521\n",
      "[1345]\tvalid_0's auc: 0.892541\n",
      "[1346]\tvalid_0's auc: 0.892552\n",
      "[1347]\tvalid_0's auc: 0.892577\n",
      "[1348]\tvalid_0's auc: 0.892577\n",
      "[1349]\tvalid_0's auc: 0.892584\n",
      "[1350]\tvalid_0's auc: 0.892606\n",
      "[1351]\tvalid_0's auc: 0.89262\n",
      "[1352]\tvalid_0's auc: 0.892613\n",
      "[1353]\tvalid_0's auc: 0.892626\n",
      "[1354]\tvalid_0's auc: 0.892634\n",
      "[1355]\tvalid_0's auc: 0.892638\n",
      "[1356]\tvalid_0's auc: 0.892632\n",
      "[1357]\tvalid_0's auc: 0.892656\n",
      "[1358]\tvalid_0's auc: 0.892651\n",
      "[1359]\tvalid_0's auc: 0.892647\n",
      "[1360]\tvalid_0's auc: 0.892661\n",
      "[1361]\tvalid_0's auc: 0.892665\n",
      "[1362]\tvalid_0's auc: 0.892693\n",
      "[1363]\tvalid_0's auc: 0.892686\n",
      "[1364]\tvalid_0's auc: 0.892707\n",
      "[1365]\tvalid_0's auc: 0.892721\n",
      "[1366]\tvalid_0's auc: 0.892731\n",
      "[1367]\tvalid_0's auc: 0.892743\n",
      "[1368]\tvalid_0's auc: 0.892753\n",
      "[1369]\tvalid_0's auc: 0.892758\n",
      "[1370]\tvalid_0's auc: 0.892776\n",
      "[1371]\tvalid_0's auc: 0.892785\n",
      "[1372]\tvalid_0's auc: 0.892784\n",
      "[1373]\tvalid_0's auc: 0.892785\n",
      "[1374]\tvalid_0's auc: 0.892786\n",
      "[1375]\tvalid_0's auc: 0.892786\n",
      "[1376]\tvalid_0's auc: 0.892821\n",
      "[1377]\tvalid_0's auc: 0.892823\n",
      "[1378]\tvalid_0's auc: 0.892818\n",
      "[1379]\tvalid_0's auc: 0.89283\n",
      "[1380]\tvalid_0's auc: 0.892856\n",
      "[1381]\tvalid_0's auc: 0.892872\n",
      "[1382]\tvalid_0's auc: 0.892901\n",
      "[1383]\tvalid_0's auc: 0.892901\n",
      "[1384]\tvalid_0's auc: 0.892948\n",
      "[1385]\tvalid_0's auc: 0.892959\n",
      "[1386]\tvalid_0's auc: 0.892965\n",
      "[1387]\tvalid_0's auc: 0.892983\n",
      "[1388]\tvalid_0's auc: 0.892979\n",
      "[1389]\tvalid_0's auc: 0.892994\n",
      "[1390]\tvalid_0's auc: 0.893008\n",
      "[1391]\tvalid_0's auc: 0.893004\n",
      "[1392]\tvalid_0's auc: 0.893022\n",
      "[1393]\tvalid_0's auc: 0.893021\n",
      "[1394]\tvalid_0's auc: 0.893004\n",
      "[1395]\tvalid_0's auc: 0.893028\n",
      "[1396]\tvalid_0's auc: 0.893043\n",
      "[1397]\tvalid_0's auc: 0.893051\n",
      "[1398]\tvalid_0's auc: 0.893048\n",
      "[1399]\tvalid_0's auc: 0.89307\n",
      "[1400]\tvalid_0's auc: 0.893089\n",
      "[1401]\tvalid_0's auc: 0.893114\n",
      "[1402]\tvalid_0's auc: 0.89314\n",
      "[1403]\tvalid_0's auc: 0.893167\n",
      "[1404]\tvalid_0's auc: 0.893162\n",
      "[1405]\tvalid_0's auc: 0.893187\n",
      "[1406]\tvalid_0's auc: 0.893187\n",
      "[1407]\tvalid_0's auc: 0.893206\n",
      "[1408]\tvalid_0's auc: 0.893228\n",
      "[1409]\tvalid_0's auc: 0.893235\n",
      "[1410]\tvalid_0's auc: 0.89324\n",
      "[1411]\tvalid_0's auc: 0.893249\n",
      "[1412]\tvalid_0's auc: 0.893264\n",
      "[1413]\tvalid_0's auc: 0.893273\n",
      "[1414]\tvalid_0's auc: 0.89329\n",
      "[1415]\tvalid_0's auc: 0.893301\n",
      "[1416]\tvalid_0's auc: 0.893311\n",
      "[1417]\tvalid_0's auc: 0.893304\n",
      "[1418]\tvalid_0's auc: 0.893307\n",
      "[1419]\tvalid_0's auc: 0.893314\n",
      "[1420]\tvalid_0's auc: 0.893326\n",
      "[1421]\tvalid_0's auc: 0.893321\n",
      "[1422]\tvalid_0's auc: 0.893333\n",
      "[1423]\tvalid_0's auc: 0.893348\n",
      "[1424]\tvalid_0's auc: 0.893341\n",
      "[1425]\tvalid_0's auc: 0.893337\n",
      "[1426]\tvalid_0's auc: 0.893344\n",
      "[1427]\tvalid_0's auc: 0.893366\n",
      "[1428]\tvalid_0's auc: 0.89337\n",
      "[1429]\tvalid_0's auc: 0.893366\n",
      "[1430]\tvalid_0's auc: 0.893372\n",
      "[1431]\tvalid_0's auc: 0.893388\n",
      "[1432]\tvalid_0's auc: 0.893398\n",
      "[1433]\tvalid_0's auc: 0.893412\n",
      "[1434]\tvalid_0's auc: 0.893399\n",
      "[1435]\tvalid_0's auc: 0.893413\n",
      "[1436]\tvalid_0's auc: 0.893425\n",
      "[1437]\tvalid_0's auc: 0.893434\n",
      "[1438]\tvalid_0's auc: 0.893431\n",
      "[1439]\tvalid_0's auc: 0.893438\n",
      "[1440]\tvalid_0's auc: 0.893444\n",
      "[1441]\tvalid_0's auc: 0.893444\n",
      "[1442]\tvalid_0's auc: 0.893447\n",
      "[1443]\tvalid_0's auc: 0.893439\n",
      "[1444]\tvalid_0's auc: 0.893443\n",
      "[1445]\tvalid_0's auc: 0.893457\n",
      "[1446]\tvalid_0's auc: 0.893466\n",
      "[1447]\tvalid_0's auc: 0.893469\n",
      "[1448]\tvalid_0's auc: 0.893464\n",
      "[1449]\tvalid_0's auc: 0.893476\n",
      "[1450]\tvalid_0's auc: 0.893478\n",
      "[1451]\tvalid_0's auc: 0.893478\n",
      "[1452]\tvalid_0's auc: 0.893517\n",
      "[1453]\tvalid_0's auc: 0.893525\n",
      "[1454]\tvalid_0's auc: 0.893515\n",
      "[1455]\tvalid_0's auc: 0.893518\n",
      "[1456]\tvalid_0's auc: 0.893519\n",
      "[1457]\tvalid_0's auc: 0.893527\n",
      "[1458]\tvalid_0's auc: 0.893526\n",
      "[1459]\tvalid_0's auc: 0.893527\n",
      "[1460]\tvalid_0's auc: 0.893529\n",
      "[1461]\tvalid_0's auc: 0.893546\n",
      "[1462]\tvalid_0's auc: 0.893559\n",
      "[1463]\tvalid_0's auc: 0.893593\n",
      "[1464]\tvalid_0's auc: 0.893615\n",
      "[1465]\tvalid_0's auc: 0.893636\n",
      "[1466]\tvalid_0's auc: 0.893655\n",
      "[1467]\tvalid_0's auc: 0.893656\n",
      "[1468]\tvalid_0's auc: 0.893672\n",
      "[1469]\tvalid_0's auc: 0.893675\n",
      "[1470]\tvalid_0's auc: 0.893693\n",
      "[1471]\tvalid_0's auc: 0.893693\n",
      "[1472]\tvalid_0's auc: 0.893715\n",
      "[1473]\tvalid_0's auc: 0.89372\n",
      "[1474]\tvalid_0's auc: 0.893726\n",
      "[1475]\tvalid_0's auc: 0.89372\n",
      "[1476]\tvalid_0's auc: 0.893726\n",
      "[1477]\tvalid_0's auc: 0.893743\n",
      "[1478]\tvalid_0's auc: 0.893756\n",
      "[1479]\tvalid_0's auc: 0.893768\n",
      "[1480]\tvalid_0's auc: 0.89378\n",
      "[1481]\tvalid_0's auc: 0.893781\n",
      "[1482]\tvalid_0's auc: 0.89378\n",
      "[1483]\tvalid_0's auc: 0.893799\n",
      "[1484]\tvalid_0's auc: 0.893803\n",
      "[1485]\tvalid_0's auc: 0.893809\n",
      "[1486]\tvalid_0's auc: 0.89382\n",
      "[1487]\tvalid_0's auc: 0.893821\n",
      "[1488]\tvalid_0's auc: 0.893819\n",
      "[1489]\tvalid_0's auc: 0.893839\n",
      "[1490]\tvalid_0's auc: 0.893856\n",
      "[1491]\tvalid_0's auc: 0.893845\n",
      "[1492]\tvalid_0's auc: 0.893833\n",
      "[1493]\tvalid_0's auc: 0.893839\n",
      "[1494]\tvalid_0's auc: 0.893842\n",
      "[1495]\tvalid_0's auc: 0.89385\n",
      "[1496]\tvalid_0's auc: 0.893858\n",
      "[1497]\tvalid_0's auc: 0.89388\n",
      "[1498]\tvalid_0's auc: 0.89389\n",
      "[1499]\tvalid_0's auc: 0.893892\n",
      "[1500]\tvalid_0's auc: 0.893897\n",
      "[1501]\tvalid_0's auc: 0.89388\n",
      "[1502]\tvalid_0's auc: 0.893892\n",
      "[1503]\tvalid_0's auc: 0.893883\n",
      "[1504]\tvalid_0's auc: 0.893883\n",
      "[1505]\tvalid_0's auc: 0.893891\n",
      "[1506]\tvalid_0's auc: 0.893904\n",
      "[1507]\tvalid_0's auc: 0.893911\n",
      "[1508]\tvalid_0's auc: 0.893919\n",
      "[1509]\tvalid_0's auc: 0.893926\n",
      "[1510]\tvalid_0's auc: 0.893927\n",
      "[1511]\tvalid_0's auc: 0.89394\n",
      "[1512]\tvalid_0's auc: 0.893938\n",
      "[1513]\tvalid_0's auc: 0.893961\n",
      "[1514]\tvalid_0's auc: 0.893966\n",
      "[1515]\tvalid_0's auc: 0.893978\n",
      "[1516]\tvalid_0's auc: 0.893986\n",
      "[1517]\tvalid_0's auc: 0.894002\n",
      "[1518]\tvalid_0's auc: 0.893994\n",
      "[1519]\tvalid_0's auc: 0.89401\n",
      "[1520]\tvalid_0's auc: 0.894041\n",
      "[1521]\tvalid_0's auc: 0.894067\n",
      "[1522]\tvalid_0's auc: 0.894069\n",
      "[1523]\tvalid_0's auc: 0.894077\n",
      "[1524]\tvalid_0's auc: 0.89408\n",
      "[1525]\tvalid_0's auc: 0.894078\n",
      "[1526]\tvalid_0's auc: 0.89409\n",
      "[1527]\tvalid_0's auc: 0.894112\n",
      "[1528]\tvalid_0's auc: 0.894108\n",
      "[1529]\tvalid_0's auc: 0.894122\n",
      "[1530]\tvalid_0's auc: 0.894128\n",
      "[1531]\tvalid_0's auc: 0.894152\n",
      "[1532]\tvalid_0's auc: 0.894152\n",
      "[1533]\tvalid_0's auc: 0.894183\n",
      "[1534]\tvalid_0's auc: 0.8942\n",
      "[1535]\tvalid_0's auc: 0.894199\n",
      "[1536]\tvalid_0's auc: 0.894206\n",
      "[1537]\tvalid_0's auc: 0.894192\n",
      "[1538]\tvalid_0's auc: 0.894206\n",
      "[1539]\tvalid_0's auc: 0.894227\n",
      "[1540]\tvalid_0's auc: 0.894242\n",
      "[1541]\tvalid_0's auc: 0.89426\n",
      "[1542]\tvalid_0's auc: 0.894265\n",
      "[1543]\tvalid_0's auc: 0.894267\n",
      "[1544]\tvalid_0's auc: 0.894292\n",
      "[1545]\tvalid_0's auc: 0.894312\n",
      "[1546]\tvalid_0's auc: 0.894326\n",
      "[1547]\tvalid_0's auc: 0.894322\n",
      "[1548]\tvalid_0's auc: 0.894333\n",
      "[1549]\tvalid_0's auc: 0.894336\n",
      "[1550]\tvalid_0's auc: 0.894348\n",
      "[1551]\tvalid_0's auc: 0.894346\n",
      "[1552]\tvalid_0's auc: 0.894355\n",
      "[1553]\tvalid_0's auc: 0.894354\n",
      "[1554]\tvalid_0's auc: 0.894355\n",
      "[1555]\tvalid_0's auc: 0.894367\n",
      "[1556]\tvalid_0's auc: 0.894374\n",
      "[1557]\tvalid_0's auc: 0.894377\n",
      "[1558]\tvalid_0's auc: 0.89439\n",
      "[1559]\tvalid_0's auc: 0.894409\n",
      "[1560]\tvalid_0's auc: 0.894403\n",
      "[1561]\tvalid_0's auc: 0.894407\n",
      "[1562]\tvalid_0's auc: 0.894407\n",
      "[1563]\tvalid_0's auc: 0.894404\n",
      "[1564]\tvalid_0's auc: 0.894415\n",
      "[1565]\tvalid_0's auc: 0.894434\n",
      "[1566]\tvalid_0's auc: 0.894448\n",
      "[1567]\tvalid_0's auc: 0.894445\n",
      "[1568]\tvalid_0's auc: 0.894437\n",
      "[1569]\tvalid_0's auc: 0.894451\n",
      "[1570]\tvalid_0's auc: 0.89445\n",
      "[1571]\tvalid_0's auc: 0.894465\n",
      "[1572]\tvalid_0's auc: 0.894472\n",
      "[1573]\tvalid_0's auc: 0.894459\n",
      "[1574]\tvalid_0's auc: 0.894475\n",
      "[1575]\tvalid_0's auc: 0.89449\n",
      "[1576]\tvalid_0's auc: 0.894514\n",
      "[1577]\tvalid_0's auc: 0.894516\n",
      "[1578]\tvalid_0's auc: 0.894528\n",
      "[1579]\tvalid_0's auc: 0.894559\n",
      "[1580]\tvalid_0's auc: 0.894571\n",
      "[1581]\tvalid_0's auc: 0.894576\n",
      "[1582]\tvalid_0's auc: 0.894576\n",
      "[1583]\tvalid_0's auc: 0.894571\n",
      "[1584]\tvalid_0's auc: 0.894554\n",
      "[1585]\tvalid_0's auc: 0.894556\n",
      "[1586]\tvalid_0's auc: 0.894569\n",
      "[1587]\tvalid_0's auc: 0.894562\n",
      "[1588]\tvalid_0's auc: 0.894569\n",
      "[1589]\tvalid_0's auc: 0.894556\n",
      "[1590]\tvalid_0's auc: 0.89456\n",
      "[1591]\tvalid_0's auc: 0.89457\n",
      "[1592]\tvalid_0's auc: 0.894568\n",
      "[1593]\tvalid_0's auc: 0.894574\n",
      "[1594]\tvalid_0's auc: 0.894576\n",
      "[1595]\tvalid_0's auc: 0.894593\n",
      "[1596]\tvalid_0's auc: 0.894598\n",
      "[1597]\tvalid_0's auc: 0.894624\n",
      "[1598]\tvalid_0's auc: 0.894611\n",
      "[1599]\tvalid_0's auc: 0.894619\n",
      "[1600]\tvalid_0's auc: 0.894619\n",
      "[1601]\tvalid_0's auc: 0.894637\n",
      "[1602]\tvalid_0's auc: 0.89466\n",
      "[1603]\tvalid_0's auc: 0.894674\n",
      "[1604]\tvalid_0's auc: 0.89469\n",
      "[1605]\tvalid_0's auc: 0.894708\n",
      "[1606]\tvalid_0's auc: 0.894712\n",
      "[1607]\tvalid_0's auc: 0.894732\n",
      "[1608]\tvalid_0's auc: 0.894754\n",
      "[1609]\tvalid_0's auc: 0.894756\n",
      "[1610]\tvalid_0's auc: 0.894766\n",
      "[1611]\tvalid_0's auc: 0.894778\n",
      "[1612]\tvalid_0's auc: 0.894782\n",
      "[1613]\tvalid_0's auc: 0.894792\n",
      "[1614]\tvalid_0's auc: 0.894804\n",
      "[1615]\tvalid_0's auc: 0.894831\n",
      "[1616]\tvalid_0's auc: 0.894846\n",
      "[1617]\tvalid_0's auc: 0.894859\n",
      "[1618]\tvalid_0's auc: 0.89486\n",
      "[1619]\tvalid_0's auc: 0.894887\n",
      "[1620]\tvalid_0's auc: 0.894894\n",
      "[1621]\tvalid_0's auc: 0.8949\n",
      "[1622]\tvalid_0's auc: 0.894899\n",
      "[1623]\tvalid_0's auc: 0.894913\n",
      "[1624]\tvalid_0's auc: 0.894921\n",
      "[1625]\tvalid_0's auc: 0.8949\n",
      "[1626]\tvalid_0's auc: 0.8949\n",
      "[1627]\tvalid_0's auc: 0.894913\n",
      "[1628]\tvalid_0's auc: 0.894929\n",
      "[1629]\tvalid_0's auc: 0.89493\n",
      "[1630]\tvalid_0's auc: 0.894921\n",
      "[1631]\tvalid_0's auc: 0.894919\n",
      "[1632]\tvalid_0's auc: 0.894905\n",
      "[1633]\tvalid_0's auc: 0.894909\n",
      "[1634]\tvalid_0's auc: 0.894916\n",
      "[1635]\tvalid_0's auc: 0.894924\n",
      "[1636]\tvalid_0's auc: 0.89494\n",
      "[1637]\tvalid_0's auc: 0.89494\n",
      "[1638]\tvalid_0's auc: 0.894947\n",
      "[1639]\tvalid_0's auc: 0.894971\n",
      "[1640]\tvalid_0's auc: 0.894976\n",
      "[1641]\tvalid_0's auc: 0.894965\n",
      "[1642]\tvalid_0's auc: 0.894981\n",
      "[1643]\tvalid_0's auc: 0.895002\n",
      "[1644]\tvalid_0's auc: 0.89502\n",
      "[1645]\tvalid_0's auc: 0.895019\n",
      "[1646]\tvalid_0's auc: 0.895049\n",
      "[1647]\tvalid_0's auc: 0.895074\n",
      "[1648]\tvalid_0's auc: 0.895082\n",
      "[1649]\tvalid_0's auc: 0.895118\n",
      "[1650]\tvalid_0's auc: 0.895125\n",
      "[1651]\tvalid_0's auc: 0.89513\n",
      "[1652]\tvalid_0's auc: 0.895158\n",
      "[1653]\tvalid_0's auc: 0.895157\n",
      "[1654]\tvalid_0's auc: 0.895158\n",
      "[1655]\tvalid_0's auc: 0.895165\n",
      "[1656]\tvalid_0's auc: 0.895184\n",
      "[1657]\tvalid_0's auc: 0.895183\n",
      "[1658]\tvalid_0's auc: 0.895195\n",
      "[1659]\tvalid_0's auc: 0.89521\n",
      "[1660]\tvalid_0's auc: 0.895231\n",
      "[1661]\tvalid_0's auc: 0.895233\n",
      "[1662]\tvalid_0's auc: 0.895237\n",
      "[1663]\tvalid_0's auc: 0.895253\n",
      "[1664]\tvalid_0's auc: 0.895244\n",
      "[1665]\tvalid_0's auc: 0.895263\n",
      "[1666]\tvalid_0's auc: 0.895263\n",
      "[1667]\tvalid_0's auc: 0.895278\n",
      "[1668]\tvalid_0's auc: 0.89529\n",
      "[1669]\tvalid_0's auc: 0.895299\n",
      "[1670]\tvalid_0's auc: 0.895309\n",
      "[1671]\tvalid_0's auc: 0.895311\n",
      "[1672]\tvalid_0's auc: 0.895326\n",
      "[1673]\tvalid_0's auc: 0.89533\n",
      "[1674]\tvalid_0's auc: 0.895329\n",
      "[1675]\tvalid_0's auc: 0.89533\n",
      "[1676]\tvalid_0's auc: 0.895337\n",
      "[1677]\tvalid_0's auc: 0.895345\n",
      "[1678]\tvalid_0's auc: 0.895344\n",
      "[1679]\tvalid_0's auc: 0.895361\n",
      "[1680]\tvalid_0's auc: 0.895371\n",
      "[1681]\tvalid_0's auc: 0.895381\n",
      "[1682]\tvalid_0's auc: 0.895393\n",
      "[1683]\tvalid_0's auc: 0.895404\n",
      "[1684]\tvalid_0's auc: 0.8954\n",
      "[1685]\tvalid_0's auc: 0.895402\n",
      "[1686]\tvalid_0's auc: 0.895417\n",
      "[1687]\tvalid_0's auc: 0.895428\n",
      "[1688]\tvalid_0's auc: 0.895425\n",
      "[1689]\tvalid_0's auc: 0.895432\n",
      "[1690]\tvalid_0's auc: 0.895452\n",
      "[1691]\tvalid_0's auc: 0.895453\n",
      "[1692]\tvalid_0's auc: 0.895474\n",
      "[1693]\tvalid_0's auc: 0.895469\n",
      "[1694]\tvalid_0's auc: 0.895474\n",
      "[1695]\tvalid_0's auc: 0.89548\n",
      "[1696]\tvalid_0's auc: 0.895487\n",
      "[1697]\tvalid_0's auc: 0.895512\n",
      "[1698]\tvalid_0's auc: 0.895534\n",
      "[1699]\tvalid_0's auc: 0.895544\n",
      "[1700]\tvalid_0's auc: 0.895562\n",
      "[1701]\tvalid_0's auc: 0.895569\n",
      "[1702]\tvalid_0's auc: 0.895559\n",
      "[1703]\tvalid_0's auc: 0.895584\n",
      "[1704]\tvalid_0's auc: 0.895586\n",
      "[1705]\tvalid_0's auc: 0.89559\n",
      "[1706]\tvalid_0's auc: 0.895583\n",
      "[1707]\tvalid_0's auc: 0.895581\n",
      "[1708]\tvalid_0's auc: 0.895573\n",
      "[1709]\tvalid_0's auc: 0.895568\n",
      "[1710]\tvalid_0's auc: 0.895576\n",
      "[1711]\tvalid_0's auc: 0.895581\n",
      "[1712]\tvalid_0's auc: 0.895584\n",
      "[1713]\tvalid_0's auc: 0.895582\n",
      "[1714]\tvalid_0's auc: 0.895589\n",
      "[1715]\tvalid_0's auc: 0.895587\n",
      "[1716]\tvalid_0's auc: 0.895583\n",
      "[1717]\tvalid_0's auc: 0.895572\n",
      "[1718]\tvalid_0's auc: 0.895581\n",
      "[1719]\tvalid_0's auc: 0.895586\n",
      "[1720]\tvalid_0's auc: 0.895598\n",
      "[1721]\tvalid_0's auc: 0.895615\n",
      "[1722]\tvalid_0's auc: 0.895609\n",
      "[1723]\tvalid_0's auc: 0.895614\n",
      "[1724]\tvalid_0's auc: 0.89561\n",
      "[1725]\tvalid_0's auc: 0.895602\n",
      "[1726]\tvalid_0's auc: 0.895604\n",
      "[1727]\tvalid_0's auc: 0.895606\n",
      "[1728]\tvalid_0's auc: 0.895617\n",
      "[1729]\tvalid_0's auc: 0.895614\n",
      "[1730]\tvalid_0's auc: 0.895631\n",
      "[1731]\tvalid_0's auc: 0.895629\n",
      "[1732]\tvalid_0's auc: 0.895633\n",
      "[1733]\tvalid_0's auc: 0.895641\n",
      "[1734]\tvalid_0's auc: 0.895652\n",
      "[1735]\tvalid_0's auc: 0.895657\n",
      "[1736]\tvalid_0's auc: 0.895659\n",
      "[1737]\tvalid_0's auc: 0.895661\n",
      "[1738]\tvalid_0's auc: 0.895662\n",
      "[1739]\tvalid_0's auc: 0.895686\n",
      "[1740]\tvalid_0's auc: 0.895677\n",
      "[1741]\tvalid_0's auc: 0.895686\n",
      "[1742]\tvalid_0's auc: 0.895685\n",
      "[1743]\tvalid_0's auc: 0.89568\n",
      "[1744]\tvalid_0's auc: 0.895674\n",
      "[1745]\tvalid_0's auc: 0.89568\n",
      "[1746]\tvalid_0's auc: 0.89568\n",
      "[1747]\tvalid_0's auc: 0.895688\n",
      "[1748]\tvalid_0's auc: 0.895686\n",
      "[1749]\tvalid_0's auc: 0.895703\n",
      "[1750]\tvalid_0's auc: 0.895708\n",
      "[1751]\tvalid_0's auc: 0.895715\n",
      "[1752]\tvalid_0's auc: 0.895722\n",
      "[1753]\tvalid_0's auc: 0.895708\n",
      "[1754]\tvalid_0's auc: 0.89573\n",
      "[1755]\tvalid_0's auc: 0.895742\n",
      "[1756]\tvalid_0's auc: 0.895749\n",
      "[1757]\tvalid_0's auc: 0.895752\n",
      "[1758]\tvalid_0's auc: 0.895736\n",
      "[1759]\tvalid_0's auc: 0.89575\n",
      "[1760]\tvalid_0's auc: 0.895763\n",
      "[1761]\tvalid_0's auc: 0.895759\n",
      "[1762]\tvalid_0's auc: 0.89578\n",
      "[1763]\tvalid_0's auc: 0.895777\n",
      "[1764]\tvalid_0's auc: 0.895781\n",
      "[1765]\tvalid_0's auc: 0.895794\n",
      "[1766]\tvalid_0's auc: 0.895801\n",
      "[1767]\tvalid_0's auc: 0.895809\n",
      "[1768]\tvalid_0's auc: 0.895831\n",
      "[1769]\tvalid_0's auc: 0.895846\n",
      "[1770]\tvalid_0's auc: 0.895841\n",
      "[1771]\tvalid_0's auc: 0.895842\n",
      "[1772]\tvalid_0's auc: 0.895858\n",
      "[1773]\tvalid_0's auc: 0.895862\n",
      "[1774]\tvalid_0's auc: 0.895872\n",
      "[1775]\tvalid_0's auc: 0.895876\n",
      "[1776]\tvalid_0's auc: 0.895889\n",
      "[1777]\tvalid_0's auc: 0.89591\n",
      "[1778]\tvalid_0's auc: 0.895912\n",
      "[1779]\tvalid_0's auc: 0.895918\n",
      "[1780]\tvalid_0's auc: 0.89592\n",
      "[1781]\tvalid_0's auc: 0.895913\n",
      "[1782]\tvalid_0's auc: 0.895909\n",
      "[1783]\tvalid_0's auc: 0.895907\n",
      "[1784]\tvalid_0's auc: 0.895909\n",
      "[1785]\tvalid_0's auc: 0.895915\n",
      "[1786]\tvalid_0's auc: 0.895905\n",
      "[1787]\tvalid_0's auc: 0.895893\n",
      "[1788]\tvalid_0's auc: 0.895893\n",
      "[1789]\tvalid_0's auc: 0.895886\n",
      "[1790]\tvalid_0's auc: 0.89589\n",
      "[1791]\tvalid_0's auc: 0.895888\n",
      "[1792]\tvalid_0's auc: 0.895876\n",
      "[1793]\tvalid_0's auc: 0.895878\n",
      "[1794]\tvalid_0's auc: 0.895873\n",
      "[1795]\tvalid_0's auc: 0.895873\n",
      "[1796]\tvalid_0's auc: 0.895868\n",
      "[1797]\tvalid_0's auc: 0.895879\n",
      "[1798]\tvalid_0's auc: 0.895887\n",
      "[1799]\tvalid_0's auc: 0.895895\n",
      "[1800]\tvalid_0's auc: 0.895899\n",
      "[1801]\tvalid_0's auc: 0.895891\n",
      "[1802]\tvalid_0's auc: 0.895896\n",
      "[1803]\tvalid_0's auc: 0.895902\n",
      "[1804]\tvalid_0's auc: 0.895926\n",
      "[1805]\tvalid_0's auc: 0.89593\n",
      "[1806]\tvalid_0's auc: 0.895932\n",
      "[1807]\tvalid_0's auc: 0.895937\n",
      "[1808]\tvalid_0's auc: 0.895955\n",
      "[1809]\tvalid_0's auc: 0.895962\n",
      "[1810]\tvalid_0's auc: 0.895977\n",
      "[1811]\tvalid_0's auc: 0.895988\n",
      "[1812]\tvalid_0's auc: 0.895997\n",
      "[1813]\tvalid_0's auc: 0.895999\n",
      "[1814]\tvalid_0's auc: 0.896024\n",
      "[1815]\tvalid_0's auc: 0.896035\n",
      "[1816]\tvalid_0's auc: 0.896051\n",
      "[1817]\tvalid_0's auc: 0.896059\n",
      "[1818]\tvalid_0's auc: 0.896078\n",
      "[1819]\tvalid_0's auc: 0.896082\n",
      "[1820]\tvalid_0's auc: 0.896083\n",
      "[1821]\tvalid_0's auc: 0.89609\n",
      "[1822]\tvalid_0's auc: 0.896092\n",
      "[1823]\tvalid_0's auc: 0.896104\n",
      "[1824]\tvalid_0's auc: 0.896106\n",
      "[1825]\tvalid_0's auc: 0.896126\n",
      "[1826]\tvalid_0's auc: 0.896124\n",
      "[1827]\tvalid_0's auc: 0.896153\n",
      "[1828]\tvalid_0's auc: 0.896146\n",
      "[1829]\tvalid_0's auc: 0.896138\n",
      "[1830]\tvalid_0's auc: 0.896138\n",
      "[1831]\tvalid_0's auc: 0.896153\n",
      "[1832]\tvalid_0's auc: 0.89617\n",
      "[1833]\tvalid_0's auc: 0.896181\n",
      "[1834]\tvalid_0's auc: 0.896199\n",
      "[1835]\tvalid_0's auc: 0.896201\n",
      "[1836]\tvalid_0's auc: 0.896222\n",
      "[1837]\tvalid_0's auc: 0.896227\n",
      "[1838]\tvalid_0's auc: 0.896248\n",
      "[1839]\tvalid_0's auc: 0.896264\n",
      "[1840]\tvalid_0's auc: 0.896266\n",
      "[1841]\tvalid_0's auc: 0.896274\n",
      "[1842]\tvalid_0's auc: 0.896268\n",
      "[1843]\tvalid_0's auc: 0.896271\n",
      "[1844]\tvalid_0's auc: 0.896282\n",
      "[1845]\tvalid_0's auc: 0.896291\n",
      "[1846]\tvalid_0's auc: 0.896305\n",
      "[1847]\tvalid_0's auc: 0.896305\n",
      "[1848]\tvalid_0's auc: 0.896322\n",
      "[1849]\tvalid_0's auc: 0.896331\n",
      "[1850]\tvalid_0's auc: 0.896339\n",
      "[1851]\tvalid_0's auc: 0.896367\n",
      "[1852]\tvalid_0's auc: 0.896378\n",
      "[1853]\tvalid_0's auc: 0.896381\n",
      "[1854]\tvalid_0's auc: 0.896384\n",
      "[1855]\tvalid_0's auc: 0.896413\n",
      "[1856]\tvalid_0's auc: 0.896407\n",
      "[1857]\tvalid_0's auc: 0.896415\n",
      "[1858]\tvalid_0's auc: 0.896422\n",
      "[1859]\tvalid_0's auc: 0.896435\n",
      "[1860]\tvalid_0's auc: 0.896434\n",
      "[1861]\tvalid_0's auc: 0.896446\n",
      "[1862]\tvalid_0's auc: 0.896458\n",
      "[1863]\tvalid_0's auc: 0.896468\n",
      "[1864]\tvalid_0's auc: 0.896467\n",
      "[1865]\tvalid_0's auc: 0.896453\n",
      "[1866]\tvalid_0's auc: 0.896464\n",
      "[1867]\tvalid_0's auc: 0.89647\n",
      "[1868]\tvalid_0's auc: 0.896461\n",
      "[1869]\tvalid_0's auc: 0.896463\n",
      "[1870]\tvalid_0's auc: 0.896457\n",
      "[1871]\tvalid_0's auc: 0.89645\n",
      "[1872]\tvalid_0's auc: 0.896452\n",
      "[1873]\tvalid_0's auc: 0.896473\n",
      "[1874]\tvalid_0's auc: 0.89647\n",
      "[1875]\tvalid_0's auc: 0.896469\n",
      "[1876]\tvalid_0's auc: 0.896485\n",
      "[1877]\tvalid_0's auc: 0.896495\n",
      "[1878]\tvalid_0's auc: 0.896508\n",
      "[1879]\tvalid_0's auc: 0.896502\n",
      "[1880]\tvalid_0's auc: 0.896501\n",
      "[1881]\tvalid_0's auc: 0.896514\n",
      "[1882]\tvalid_0's auc: 0.896506\n",
      "[1883]\tvalid_0's auc: 0.896503\n",
      "[1884]\tvalid_0's auc: 0.896505\n",
      "[1885]\tvalid_0's auc: 0.896518\n",
      "[1886]\tvalid_0's auc: 0.896527\n",
      "[1887]\tvalid_0's auc: 0.896528\n",
      "[1888]\tvalid_0's auc: 0.896531\n",
      "[1889]\tvalid_0's auc: 0.896547\n",
      "[1890]\tvalid_0's auc: 0.896553\n",
      "[1891]\tvalid_0's auc: 0.896567\n",
      "[1892]\tvalid_0's auc: 0.896577\n",
      "[1893]\tvalid_0's auc: 0.896581\n",
      "[1894]\tvalid_0's auc: 0.896572\n",
      "[1895]\tvalid_0's auc: 0.896588\n",
      "[1896]\tvalid_0's auc: 0.896605\n",
      "[1897]\tvalid_0's auc: 0.896604\n",
      "[1898]\tvalid_0's auc: 0.896611\n",
      "[1899]\tvalid_0's auc: 0.896616\n",
      "[1900]\tvalid_0's auc: 0.896614\n",
      "[1901]\tvalid_0's auc: 0.896628\n",
      "[1902]\tvalid_0's auc: 0.896641\n",
      "[1903]\tvalid_0's auc: 0.896653\n",
      "[1904]\tvalid_0's auc: 0.896642\n",
      "[1905]\tvalid_0's auc: 0.896666\n",
      "[1906]\tvalid_0's auc: 0.896674\n",
      "[1907]\tvalid_0's auc: 0.896681\n",
      "[1908]\tvalid_0's auc: 0.896688\n",
      "[1909]\tvalid_0's auc: 0.896697\n",
      "[1910]\tvalid_0's auc: 0.896702\n",
      "[1911]\tvalid_0's auc: 0.896724\n",
      "[1912]\tvalid_0's auc: 0.896739\n",
      "[1913]\tvalid_0's auc: 0.896744\n",
      "[1914]\tvalid_0's auc: 0.89676\n",
      "[1915]\tvalid_0's auc: 0.896768\n",
      "[1916]\tvalid_0's auc: 0.896767\n",
      "[1917]\tvalid_0's auc: 0.896784\n",
      "[1918]\tvalid_0's auc: 0.896786\n",
      "[1919]\tvalid_0's auc: 0.896803\n",
      "[1920]\tvalid_0's auc: 0.896808\n",
      "[1921]\tvalid_0's auc: 0.896801\n",
      "[1922]\tvalid_0's auc: 0.896813\n",
      "[1923]\tvalid_0's auc: 0.896821\n",
      "[1924]\tvalid_0's auc: 0.896825\n",
      "[1925]\tvalid_0's auc: 0.896834\n",
      "[1926]\tvalid_0's auc: 0.896837\n",
      "[1927]\tvalid_0's auc: 0.896848\n",
      "[1928]\tvalid_0's auc: 0.896855\n",
      "[1929]\tvalid_0's auc: 0.896872\n",
      "[1930]\tvalid_0's auc: 0.896874\n",
      "[1931]\tvalid_0's auc: 0.896871\n",
      "[1932]\tvalid_0's auc: 0.896897\n",
      "[1933]\tvalid_0's auc: 0.8969\n",
      "[1934]\tvalid_0's auc: 0.896895\n",
      "[1935]\tvalid_0's auc: 0.896898\n",
      "[1936]\tvalid_0's auc: 0.896907\n",
      "[1937]\tvalid_0's auc: 0.896909\n",
      "[1938]\tvalid_0's auc: 0.896904\n",
      "[1939]\tvalid_0's auc: 0.896916\n",
      "[1940]\tvalid_0's auc: 0.896921\n",
      "[1941]\tvalid_0's auc: 0.896911\n",
      "[1942]\tvalid_0's auc: 0.896901\n",
      "[1943]\tvalid_0's auc: 0.896892\n",
      "[1944]\tvalid_0's auc: 0.896877\n",
      "[1945]\tvalid_0's auc: 0.896871\n",
      "[1946]\tvalid_0's auc: 0.896883\n",
      "[1947]\tvalid_0's auc: 0.896889\n",
      "[1948]\tvalid_0's auc: 0.896892\n",
      "[1949]\tvalid_0's auc: 0.896891\n",
      "[1950]\tvalid_0's auc: 0.896897\n",
      "[1951]\tvalid_0's auc: 0.896899\n",
      "[1952]\tvalid_0's auc: 0.896895\n",
      "[1953]\tvalid_0's auc: 0.896887\n",
      "[1954]\tvalid_0's auc: 0.896884\n",
      "[1955]\tvalid_0's auc: 0.896876\n",
      "[1956]\tvalid_0's auc: 0.896887\n",
      "[1957]\tvalid_0's auc: 0.896904\n",
      "[1958]\tvalid_0's auc: 0.896913\n",
      "[1959]\tvalid_0's auc: 0.896918\n",
      "[1960]\tvalid_0's auc: 0.896933\n",
      "[1961]\tvalid_0's auc: 0.89692\n",
      "[1962]\tvalid_0's auc: 0.896904\n",
      "[1963]\tvalid_0's auc: 0.896904\n",
      "[1964]\tvalid_0's auc: 0.896904\n",
      "[1965]\tvalid_0's auc: 0.89689\n",
      "[1966]\tvalid_0's auc: 0.89688\n",
      "[1967]\tvalid_0's auc: 0.896888\n",
      "[1968]\tvalid_0's auc: 0.896876\n",
      "[1969]\tvalid_0's auc: 0.896884\n",
      "[1970]\tvalid_0's auc: 0.896888\n",
      "[1971]\tvalid_0's auc: 0.896897\n",
      "[1972]\tvalid_0's auc: 0.896918\n",
      "[1973]\tvalid_0's auc: 0.896925\n",
      "[1974]\tvalid_0's auc: 0.896936\n",
      "[1975]\tvalid_0's auc: 0.896943\n",
      "[1976]\tvalid_0's auc: 0.896947\n",
      "[1977]\tvalid_0's auc: 0.896948\n",
      "[1978]\tvalid_0's auc: 0.896967\n",
      "[1979]\tvalid_0's auc: 0.896968\n",
      "[1980]\tvalid_0's auc: 0.896963\n",
      "[1981]\tvalid_0's auc: 0.896947\n",
      "[1982]\tvalid_0's auc: 0.896956\n",
      "[1983]\tvalid_0's auc: 0.896972\n",
      "[1984]\tvalid_0's auc: 0.896984\n",
      "[1985]\tvalid_0's auc: 0.89698\n",
      "[1986]\tvalid_0's auc: 0.896996\n",
      "[1987]\tvalid_0's auc: 0.897003\n",
      "[1988]\tvalid_0's auc: 0.897037\n",
      "[1989]\tvalid_0's auc: 0.897046\n",
      "[1990]\tvalid_0's auc: 0.897043\n",
      "[1991]\tvalid_0's auc: 0.897051\n",
      "[1992]\tvalid_0's auc: 0.897048\n",
      "[1993]\tvalid_0's auc: 0.897052\n",
      "[1994]\tvalid_0's auc: 0.89705\n",
      "[1995]\tvalid_0's auc: 0.897052\n",
      "[1996]\tvalid_0's auc: 0.897066\n",
      "[1997]\tvalid_0's auc: 0.897073\n",
      "[1998]\tvalid_0's auc: 0.897081\n",
      "[1999]\tvalid_0's auc: 0.897093\n",
      "[2000]\tvalid_0's auc: 0.897104\n",
      "[2001]\tvalid_0's auc: 0.897099\n",
      "[2002]\tvalid_0's auc: 0.897105\n",
      "[2003]\tvalid_0's auc: 0.897104\n",
      "[2004]\tvalid_0's auc: 0.897097\n",
      "[2005]\tvalid_0's auc: 0.897093\n",
      "[2006]\tvalid_0's auc: 0.89711\n",
      "[2007]\tvalid_0's auc: 0.897116\n",
      "[2008]\tvalid_0's auc: 0.897117\n",
      "[2009]\tvalid_0's auc: 0.897114\n",
      "[2010]\tvalid_0's auc: 0.89713\n",
      "[2011]\tvalid_0's auc: 0.897137\n",
      "[2012]\tvalid_0's auc: 0.897145\n",
      "[2013]\tvalid_0's auc: 0.89713\n",
      "[2014]\tvalid_0's auc: 0.897138\n",
      "[2015]\tvalid_0's auc: 0.897139\n",
      "[2016]\tvalid_0's auc: 0.897149\n",
      "[2017]\tvalid_0's auc: 0.897167\n",
      "[2018]\tvalid_0's auc: 0.897162\n",
      "[2019]\tvalid_0's auc: 0.897168\n",
      "[2020]\tvalid_0's auc: 0.89716\n",
      "[2021]\tvalid_0's auc: 0.897144\n",
      "[2022]\tvalid_0's auc: 0.897159\n",
      "[2023]\tvalid_0's auc: 0.897173\n",
      "[2024]\tvalid_0's auc: 0.897181\n",
      "[2025]\tvalid_0's auc: 0.897172\n",
      "[2026]\tvalid_0's auc: 0.897177\n",
      "[2027]\tvalid_0's auc: 0.897194\n",
      "[2028]\tvalid_0's auc: 0.897206\n",
      "[2029]\tvalid_0's auc: 0.897208\n",
      "[2030]\tvalid_0's auc: 0.8972\n",
      "[2031]\tvalid_0's auc: 0.897209\n",
      "[2032]\tvalid_0's auc: 0.897205\n",
      "[2033]\tvalid_0's auc: 0.897203\n",
      "[2034]\tvalid_0's auc: 0.897213\n",
      "[2035]\tvalid_0's auc: 0.897214\n",
      "[2036]\tvalid_0's auc: 0.897215\n",
      "[2037]\tvalid_0's auc: 0.897229\n",
      "[2038]\tvalid_0's auc: 0.897224\n",
      "[2039]\tvalid_0's auc: 0.897206\n",
      "[2040]\tvalid_0's auc: 0.897195\n",
      "[2041]\tvalid_0's auc: 0.8972\n",
      "[2042]\tvalid_0's auc: 0.897223\n",
      "[2043]\tvalid_0's auc: 0.897228\n",
      "[2044]\tvalid_0's auc: 0.897251\n",
      "[2045]\tvalid_0's auc: 0.89726\n",
      "[2046]\tvalid_0's auc: 0.897262\n",
      "[2047]\tvalid_0's auc: 0.897254\n",
      "[2048]\tvalid_0's auc: 0.897255\n",
      "[2049]\tvalid_0's auc: 0.897252\n",
      "[2050]\tvalid_0's auc: 0.897253\n",
      "[2051]\tvalid_0's auc: 0.897268\n",
      "[2052]\tvalid_0's auc: 0.897276\n",
      "[2053]\tvalid_0's auc: 0.897278\n",
      "[2054]\tvalid_0's auc: 0.897266\n",
      "[2055]\tvalid_0's auc: 0.897254\n",
      "[2056]\tvalid_0's auc: 0.897254\n",
      "[2057]\tvalid_0's auc: 0.897264\n",
      "[2058]\tvalid_0's auc: 0.897272\n",
      "[2059]\tvalid_0's auc: 0.897279\n",
      "[2060]\tvalid_0's auc: 0.897293\n",
      "[2061]\tvalid_0's auc: 0.897295\n",
      "[2062]\tvalid_0's auc: 0.89729\n",
      "[2063]\tvalid_0's auc: 0.897301\n",
      "[2064]\tvalid_0's auc: 0.897307\n",
      "[2065]\tvalid_0's auc: 0.897311\n",
      "[2066]\tvalid_0's auc: 0.89731\n",
      "[2067]\tvalid_0's auc: 0.897308\n",
      "[2068]\tvalid_0's auc: 0.897314\n",
      "[2069]\tvalid_0's auc: 0.897315\n",
      "[2070]\tvalid_0's auc: 0.897314\n",
      "[2071]\tvalid_0's auc: 0.897312\n",
      "[2072]\tvalid_0's auc: 0.897311\n",
      "[2073]\tvalid_0's auc: 0.897316\n",
      "[2074]\tvalid_0's auc: 0.897316\n",
      "[2075]\tvalid_0's auc: 0.897332\n",
      "[2076]\tvalid_0's auc: 0.897342\n",
      "[2077]\tvalid_0's auc: 0.897343\n",
      "[2078]\tvalid_0's auc: 0.897353\n",
      "[2079]\tvalid_0's auc: 0.897341\n",
      "[2080]\tvalid_0's auc: 0.897342\n",
      "[2081]\tvalid_0's auc: 0.897354\n",
      "[2082]\tvalid_0's auc: 0.897345\n",
      "[2083]\tvalid_0's auc: 0.897339\n",
      "[2084]\tvalid_0's auc: 0.897339\n",
      "[2085]\tvalid_0's auc: 0.897343\n",
      "[2086]\tvalid_0's auc: 0.897341\n",
      "[2087]\tvalid_0's auc: 0.897324\n",
      "[2088]\tvalid_0's auc: 0.897323\n",
      "[2089]\tvalid_0's auc: 0.897335\n",
      "[2090]\tvalid_0's auc: 0.897338\n",
      "[2091]\tvalid_0's auc: 0.89733\n",
      "[2092]\tvalid_0's auc: 0.897326\n",
      "[2093]\tvalid_0's auc: 0.897327\n",
      "[2094]\tvalid_0's auc: 0.897331\n",
      "[2095]\tvalid_0's auc: 0.897326\n",
      "[2096]\tvalid_0's auc: 0.897323\n",
      "[2097]\tvalid_0's auc: 0.897328\n",
      "[2098]\tvalid_0's auc: 0.89733\n",
      "[2099]\tvalid_0's auc: 0.897326\n",
      "[2100]\tvalid_0's auc: 0.897341\n",
      "[2101]\tvalid_0's auc: 0.89735\n",
      "[2102]\tvalid_0's auc: 0.897352\n",
      "[2103]\tvalid_0's auc: 0.897361\n",
      "[2104]\tvalid_0's auc: 0.897382\n",
      "[2105]\tvalid_0's auc: 0.897382\n",
      "[2106]\tvalid_0's auc: 0.897385\n",
      "[2107]\tvalid_0's auc: 0.897384\n",
      "[2108]\tvalid_0's auc: 0.897398\n",
      "[2109]\tvalid_0's auc: 0.897406\n",
      "[2110]\tvalid_0's auc: 0.897404\n",
      "[2111]\tvalid_0's auc: 0.897413\n",
      "[2112]\tvalid_0's auc: 0.897425\n",
      "[2113]\tvalid_0's auc: 0.897433\n",
      "[2114]\tvalid_0's auc: 0.897457\n",
      "[2115]\tvalid_0's auc: 0.897457\n",
      "[2116]\tvalid_0's auc: 0.897446\n",
      "[2117]\tvalid_0's auc: 0.897449\n",
      "[2118]\tvalid_0's auc: 0.897448\n",
      "[2119]\tvalid_0's auc: 0.897448\n",
      "[2120]\tvalid_0's auc: 0.897454\n",
      "[2121]\tvalid_0's auc: 0.897439\n",
      "[2122]\tvalid_0's auc: 0.897426\n",
      "[2123]\tvalid_0's auc: 0.897418\n",
      "[2124]\tvalid_0's auc: 0.897412\n",
      "[2125]\tvalid_0's auc: 0.897403\n",
      "[2126]\tvalid_0's auc: 0.897403\n",
      "[2127]\tvalid_0's auc: 0.897401\n",
      "[2128]\tvalid_0's auc: 0.897404\n",
      "[2129]\tvalid_0's auc: 0.897409\n",
      "[2130]\tvalid_0's auc: 0.897419\n",
      "[2131]\tvalid_0's auc: 0.897406\n",
      "[2132]\tvalid_0's auc: 0.897404\n",
      "[2133]\tvalid_0's auc: 0.897412\n",
      "[2134]\tvalid_0's auc: 0.8974\n",
      "[2135]\tvalid_0's auc: 0.897397\n",
      "[2136]\tvalid_0's auc: 0.89741\n",
      "[2137]\tvalid_0's auc: 0.897411\n",
      "[2138]\tvalid_0's auc: 0.897407\n",
      "[2139]\tvalid_0's auc: 0.897393\n",
      "[2140]\tvalid_0's auc: 0.897386\n",
      "[2141]\tvalid_0's auc: 0.897396\n",
      "[2142]\tvalid_0's auc: 0.897397\n",
      "[2143]\tvalid_0's auc: 0.897409\n",
      "[2144]\tvalid_0's auc: 0.897402\n",
      "[2145]\tvalid_0's auc: 0.897413\n",
      "[2146]\tvalid_0's auc: 0.897412\n",
      "[2147]\tvalid_0's auc: 0.897418\n",
      "[2148]\tvalid_0's auc: 0.897425\n",
      "[2149]\tvalid_0's auc: 0.897436\n",
      "[2150]\tvalid_0's auc: 0.897437\n",
      "[2151]\tvalid_0's auc: 0.897455\n",
      "[2152]\tvalid_0's auc: 0.897471\n",
      "[2153]\tvalid_0's auc: 0.897476\n",
      "[2154]\tvalid_0's auc: 0.897488\n",
      "[2155]\tvalid_0's auc: 0.897489\n",
      "[2156]\tvalid_0's auc: 0.897494\n",
      "[2157]\tvalid_0's auc: 0.897498\n",
      "[2158]\tvalid_0's auc: 0.897494\n",
      "[2159]\tvalid_0's auc: 0.8975\n",
      "[2160]\tvalid_0's auc: 0.897498\n",
      "[2161]\tvalid_0's auc: 0.897501\n",
      "[2162]\tvalid_0's auc: 0.897506\n",
      "[2163]\tvalid_0's auc: 0.897504\n",
      "[2164]\tvalid_0's auc: 0.897514\n",
      "[2165]\tvalid_0's auc: 0.897503\n",
      "[2166]\tvalid_0's auc: 0.897495\n",
      "[2167]\tvalid_0's auc: 0.897507\n",
      "[2168]\tvalid_0's auc: 0.897519\n",
      "[2169]\tvalid_0's auc: 0.89751\n",
      "[2170]\tvalid_0's auc: 0.89751\n",
      "[2171]\tvalid_0's auc: 0.897532\n",
      "[2172]\tvalid_0's auc: 0.897535\n",
      "[2173]\tvalid_0's auc: 0.897535\n",
      "[2174]\tvalid_0's auc: 0.897532\n",
      "[2175]\tvalid_0's auc: 0.897529\n",
      "[2176]\tvalid_0's auc: 0.897529\n",
      "[2177]\tvalid_0's auc: 0.897537\n",
      "[2178]\tvalid_0's auc: 0.897539\n",
      "[2179]\tvalid_0's auc: 0.89755\n",
      "[2180]\tvalid_0's auc: 0.897549\n",
      "[2181]\tvalid_0's auc: 0.897556\n",
      "[2182]\tvalid_0's auc: 0.897565\n",
      "[2183]\tvalid_0's auc: 0.897573\n",
      "[2184]\tvalid_0's auc: 0.897585\n",
      "[2185]\tvalid_0's auc: 0.897594\n",
      "[2186]\tvalid_0's auc: 0.89761\n",
      "[2187]\tvalid_0's auc: 0.897614\n",
      "[2188]\tvalid_0's auc: 0.89762\n",
      "[2189]\tvalid_0's auc: 0.897624\n",
      "[2190]\tvalid_0's auc: 0.897639\n",
      "[2191]\tvalid_0's auc: 0.897639\n",
      "[2192]\tvalid_0's auc: 0.897623\n",
      "[2193]\tvalid_0's auc: 0.897625\n",
      "[2194]\tvalid_0's auc: 0.897629\n",
      "[2195]\tvalid_0's auc: 0.897624\n",
      "[2196]\tvalid_0's auc: 0.897625\n",
      "[2197]\tvalid_0's auc: 0.897617\n",
      "[2198]\tvalid_0's auc: 0.897626\n",
      "[2199]\tvalid_0's auc: 0.897628\n",
      "[2200]\tvalid_0's auc: 0.897623\n",
      "[2201]\tvalid_0's auc: 0.897627\n",
      "[2202]\tvalid_0's auc: 0.897631\n",
      "[2203]\tvalid_0's auc: 0.897633\n",
      "[2204]\tvalid_0's auc: 0.897631\n",
      "[2205]\tvalid_0's auc: 0.897639\n",
      "[2206]\tvalid_0's auc: 0.897638\n",
      "[2207]\tvalid_0's auc: 0.897626\n",
      "[2208]\tvalid_0's auc: 0.897628\n",
      "[2209]\tvalid_0's auc: 0.897654\n",
      "[2210]\tvalid_0's auc: 0.897659\n",
      "[2211]\tvalid_0's auc: 0.897656\n",
      "[2212]\tvalid_0's auc: 0.897663\n",
      "[2213]\tvalid_0's auc: 0.897674\n",
      "[2214]\tvalid_0's auc: 0.897686\n",
      "[2215]\tvalid_0's auc: 0.897687\n",
      "[2216]\tvalid_0's auc: 0.897681\n",
      "[2217]\tvalid_0's auc: 0.897679\n",
      "[2218]\tvalid_0's auc: 0.897698\n",
      "[2219]\tvalid_0's auc: 0.897694\n",
      "[2220]\tvalid_0's auc: 0.897691\n",
      "[2221]\tvalid_0's auc: 0.897694\n",
      "[2222]\tvalid_0's auc: 0.897702\n",
      "[2223]\tvalid_0's auc: 0.897707\n",
      "[2224]\tvalid_0's auc: 0.897707\n",
      "[2225]\tvalid_0's auc: 0.897708\n",
      "[2226]\tvalid_0's auc: 0.897696\n",
      "[2227]\tvalid_0's auc: 0.897696\n",
      "[2228]\tvalid_0's auc: 0.897698\n",
      "[2229]\tvalid_0's auc: 0.897696\n",
      "[2230]\tvalid_0's auc: 0.897705\n",
      "[2231]\tvalid_0's auc: 0.897709\n",
      "[2232]\tvalid_0's auc: 0.897725\n",
      "[2233]\tvalid_0's auc: 0.897739\n",
      "[2234]\tvalid_0's auc: 0.897758\n",
      "[2235]\tvalid_0's auc: 0.897762\n",
      "[2236]\tvalid_0's auc: 0.897762\n",
      "[2237]\tvalid_0's auc: 0.897762\n",
      "[2238]\tvalid_0's auc: 0.897773\n",
      "[2239]\tvalid_0's auc: 0.897784\n",
      "[2240]\tvalid_0's auc: 0.897787\n",
      "[2241]\tvalid_0's auc: 0.897787\n",
      "[2242]\tvalid_0's auc: 0.897789\n",
      "[2243]\tvalid_0's auc: 0.897784\n",
      "[2244]\tvalid_0's auc: 0.897781\n",
      "[2245]\tvalid_0's auc: 0.897787\n",
      "[2246]\tvalid_0's auc: 0.897785\n",
      "[2247]\tvalid_0's auc: 0.897783\n",
      "[2248]\tvalid_0's auc: 0.897796\n",
      "[2249]\tvalid_0's auc: 0.897797\n",
      "[2250]\tvalid_0's auc: 0.897789\n",
      "[2251]\tvalid_0's auc: 0.897782\n",
      "[2252]\tvalid_0's auc: 0.897787\n",
      "[2253]\tvalid_0's auc: 0.897779\n",
      "[2254]\tvalid_0's auc: 0.897791\n",
      "[2255]\tvalid_0's auc: 0.897801\n",
      "[2256]\tvalid_0's auc: 0.897812\n",
      "[2257]\tvalid_0's auc: 0.897832\n",
      "[2258]\tvalid_0's auc: 0.897839\n",
      "[2259]\tvalid_0's auc: 0.897836\n",
      "[2260]\tvalid_0's auc: 0.897847\n",
      "[2261]\tvalid_0's auc: 0.897865\n",
      "[2262]\tvalid_0's auc: 0.897868\n",
      "[2263]\tvalid_0's auc: 0.897877\n",
      "[2264]\tvalid_0's auc: 0.897872\n",
      "[2265]\tvalid_0's auc: 0.897878\n",
      "[2266]\tvalid_0's auc: 0.897887\n",
      "[2267]\tvalid_0's auc: 0.897889\n",
      "[2268]\tvalid_0's auc: 0.897906\n",
      "[2269]\tvalid_0's auc: 0.897908\n",
      "[2270]\tvalid_0's auc: 0.897915\n",
      "[2271]\tvalid_0's auc: 0.897913\n",
      "[2272]\tvalid_0's auc: 0.897913\n",
      "[2273]\tvalid_0's auc: 0.897916\n",
      "[2274]\tvalid_0's auc: 0.897911\n",
      "[2275]\tvalid_0's auc: 0.897923\n",
      "[2276]\tvalid_0's auc: 0.897925\n",
      "[2277]\tvalid_0's auc: 0.897909\n",
      "[2278]\tvalid_0's auc: 0.89791\n",
      "[2279]\tvalid_0's auc: 0.897909\n",
      "[2280]\tvalid_0's auc: 0.897893\n",
      "[2281]\tvalid_0's auc: 0.897895\n",
      "[2282]\tvalid_0's auc: 0.897885\n",
      "[2283]\tvalid_0's auc: 0.897891\n",
      "[2284]\tvalid_0's auc: 0.897891\n",
      "[2285]\tvalid_0's auc: 0.897889\n",
      "[2286]\tvalid_0's auc: 0.897895\n",
      "[2287]\tvalid_0's auc: 0.897909\n",
      "[2288]\tvalid_0's auc: 0.897914\n",
      "[2289]\tvalid_0's auc: 0.897917\n",
      "[2290]\tvalid_0's auc: 0.89793\n",
      "[2291]\tvalid_0's auc: 0.897934\n",
      "[2292]\tvalid_0's auc: 0.897938\n",
      "[2293]\tvalid_0's auc: 0.897942\n",
      "[2294]\tvalid_0's auc: 0.897941\n",
      "[2295]\tvalid_0's auc: 0.897925\n",
      "[2296]\tvalid_0's auc: 0.897939\n",
      "[2297]\tvalid_0's auc: 0.897954\n",
      "[2298]\tvalid_0's auc: 0.897944\n",
      "[2299]\tvalid_0's auc: 0.897941\n",
      "[2300]\tvalid_0's auc: 0.897941\n",
      "[2301]\tvalid_0's auc: 0.897938\n",
      "[2302]\tvalid_0's auc: 0.897942\n",
      "[2303]\tvalid_0's auc: 0.897945\n",
      "[2304]\tvalid_0's auc: 0.897949\n",
      "[2305]\tvalid_0's auc: 0.897955\n",
      "[2306]\tvalid_0's auc: 0.897951\n",
      "[2307]\tvalid_0's auc: 0.897958\n",
      "[2308]\tvalid_0's auc: 0.897974\n",
      "[2309]\tvalid_0's auc: 0.897982\n",
      "[2310]\tvalid_0's auc: 0.897979\n",
      "[2311]\tvalid_0's auc: 0.897979\n",
      "[2312]\tvalid_0's auc: 0.897982\n",
      "[2313]\tvalid_0's auc: 0.897978\n",
      "[2314]\tvalid_0's auc: 0.897988\n",
      "[2315]\tvalid_0's auc: 0.897978\n",
      "[2316]\tvalid_0's auc: 0.897983\n",
      "[2317]\tvalid_0's auc: 0.897989\n",
      "[2318]\tvalid_0's auc: 0.897988\n",
      "[2319]\tvalid_0's auc: 0.897995\n",
      "[2320]\tvalid_0's auc: 0.897983\n",
      "[2321]\tvalid_0's auc: 0.897993\n",
      "[2322]\tvalid_0's auc: 0.897994\n",
      "[2323]\tvalid_0's auc: 0.897981\n",
      "[2324]\tvalid_0's auc: 0.898004\n",
      "[2325]\tvalid_0's auc: 0.89802\n",
      "[2326]\tvalid_0's auc: 0.898017\n",
      "[2327]\tvalid_0's auc: 0.898017\n",
      "[2328]\tvalid_0's auc: 0.898019\n",
      "[2329]\tvalid_0's auc: 0.898019\n",
      "[2330]\tvalid_0's auc: 0.89802\n",
      "[2331]\tvalid_0's auc: 0.898018\n",
      "[2332]\tvalid_0's auc: 0.89803\n",
      "[2333]\tvalid_0's auc: 0.89804\n",
      "[2334]\tvalid_0's auc: 0.898039\n",
      "[2335]\tvalid_0's auc: 0.898036\n",
      "[2336]\tvalid_0's auc: 0.898042\n",
      "[2337]\tvalid_0's auc: 0.898045\n",
      "[2338]\tvalid_0's auc: 0.898053\n",
      "[2339]\tvalid_0's auc: 0.898066\n",
      "[2340]\tvalid_0's auc: 0.898064\n",
      "[2341]\tvalid_0's auc: 0.898086\n",
      "[2342]\tvalid_0's auc: 0.898084\n",
      "[2343]\tvalid_0's auc: 0.898092\n",
      "[2344]\tvalid_0's auc: 0.898087\n",
      "[2345]\tvalid_0's auc: 0.898091\n",
      "[2346]\tvalid_0's auc: 0.898104\n",
      "[2347]\tvalid_0's auc: 0.898097\n",
      "[2348]\tvalid_0's auc: 0.898095\n",
      "[2349]\tvalid_0's auc: 0.898106\n",
      "[2350]\tvalid_0's auc: 0.898098\n",
      "[2351]\tvalid_0's auc: 0.898079\n",
      "[2352]\tvalid_0's auc: 0.898071\n",
      "[2353]\tvalid_0's auc: 0.898068\n",
      "[2354]\tvalid_0's auc: 0.898059\n",
      "[2355]\tvalid_0's auc: 0.898053\n",
      "[2356]\tvalid_0's auc: 0.898054\n",
      "[2357]\tvalid_0's auc: 0.898058\n",
      "[2358]\tvalid_0's auc: 0.898038\n",
      "[2359]\tvalid_0's auc: 0.898048\n",
      "[2360]\tvalid_0's auc: 0.898034\n",
      "[2361]\tvalid_0's auc: 0.89803\n",
      "[2362]\tvalid_0's auc: 0.89803\n",
      "[2363]\tvalid_0's auc: 0.898021\n",
      "[2364]\tvalid_0's auc: 0.898022\n",
      "[2365]\tvalid_0's auc: 0.898013\n",
      "[2366]\tvalid_0's auc: 0.898008\n",
      "[2367]\tvalid_0's auc: 0.898014\n",
      "[2368]\tvalid_0's auc: 0.898022\n",
      "[2369]\tvalid_0's auc: 0.89802\n",
      "[2370]\tvalid_0's auc: 0.898015\n",
      "[2371]\tvalid_0's auc: 0.898006\n",
      "[2372]\tvalid_0's auc: 0.898009\n",
      "[2373]\tvalid_0's auc: 0.897998\n",
      "[2374]\tvalid_0's auc: 0.897999\n",
      "[2375]\tvalid_0's auc: 0.89799\n",
      "[2376]\tvalid_0's auc: 0.897993\n",
      "[2377]\tvalid_0's auc: 0.897968\n",
      "[2378]\tvalid_0's auc: 0.897956\n",
      "[2379]\tvalid_0's auc: 0.897945\n",
      "[2380]\tvalid_0's auc: 0.897944\n",
      "[2381]\tvalid_0's auc: 0.897939\n",
      "[2382]\tvalid_0's auc: 0.897945\n",
      "[2383]\tvalid_0's auc: 0.897936\n",
      "[2384]\tvalid_0's auc: 0.897935\n",
      "[2385]\tvalid_0's auc: 0.897924\n",
      "[2386]\tvalid_0's auc: 0.897908\n",
      "[2387]\tvalid_0's auc: 0.897891\n",
      "[2388]\tvalid_0's auc: 0.897902\n",
      "[2389]\tvalid_0's auc: 0.897904\n",
      "[2390]\tvalid_0's auc: 0.897906\n",
      "[2391]\tvalid_0's auc: 0.89791\n",
      "[2392]\tvalid_0's auc: 0.897906\n",
      "[2393]\tvalid_0's auc: 0.897918\n",
      "[2394]\tvalid_0's auc: 0.897908\n",
      "[2395]\tvalid_0's auc: 0.897911\n",
      "[2396]\tvalid_0's auc: 0.897904\n",
      "[2397]\tvalid_0's auc: 0.897922\n",
      "[2398]\tvalid_0's auc: 0.89793\n",
      "[2399]\tvalid_0's auc: 0.897942\n",
      "Early stopping, best iteration is:\n",
      "[2349]\tvalid_0's auc: 0.898106\n"
     ]
    }
   ],
   "source": [
    "model_lgbm = lightgbm.train(parameters,\n",
    "                            train_data,\n",
    "                            valid_sets=valid_data,\n",
    "                            num_boost_round=5000,\n",
    "                            early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e517de4-3a9b-4090-9e80-6e9b106e34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train: 0.9882\n",
      "AUC Valid: 0.8981\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_lgbm.predict(X_train)\n",
    "y_val_pred = model_lgbm.predict(X_val)\n",
    "\n",
    "print(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n",
    "                                                    roc_auc_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56e6d5-9837-4413-ad07-a191d00e6242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
